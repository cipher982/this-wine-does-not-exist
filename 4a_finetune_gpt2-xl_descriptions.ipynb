{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:26:11.936948Z",
     "start_time": "2020-08-19T20:26:10.133904Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add tokens from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:26:20.975420Z",
     "start_time": "2020-08-19T20:26:18.374311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6858708c8944d48d7faf996afd85c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510cbd75da5545fe87f021f32cc6796c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50257\n",
      "50257\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2-xl')\n",
    "print(tokenizer.vocab_size)\n",
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:26:31.132709Z",
     "start_time": "2020-08-19T20:26:31.122710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n",
      "50258\n"
     ]
    }
   ],
   "source": [
    "tokenizer.add_special_tokens(\n",
    "  {'eos_token':'<|startoftext|>',\n",
    "   'bos_token':'<|startoftext|>'\n",
    "  }\n",
    ")\n",
    "\n",
    "print(tokenizer.vocab_size)\n",
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:26:34.056610Z",
     "start_time": "2020-08-19T20:26:34.051636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n",
      "50260\n"
     ]
    }
   ],
   "source": [
    "tokenizer.add_tokens(['[prompt]','[response]'])\n",
    "\n",
    "print(tokenizer.vocab_size)\n",
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T21:12:10.807551Z",
     "start_time": "2020-08-19T21:12:10.248520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/modeling/gpt2_xl_model/vocab.json',\n",
       " 'data/modeling/gpt2_xl_model/merges.txt',\n",
       " 'data/modeling/gpt2_xl_model/special_tokens_map.json',\n",
       " 'data/modeling/gpt2_xl_model/added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('data/modeling/gpt2_xl_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GPT2 model to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:28:46.141419Z",
     "start_time": "2020-08-19T20:28:46.137419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 1557.62M\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelWithLMHead.from_pretrained('gpt2-xl')\n",
    "print(f\"Total parameters: {model.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:27:38.805955Z",
     "start_time": "2020-08-19T20:27:37.949953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 1600)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T21:12:21.141884Z",
     "start_time": "2020-08-19T21:12:12.511335Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('data/modeling/gpt2_xl_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the method in which Jupyter processes shell commands it won't show STDOUT live, only outputting once the run is finished. So I prefer to just paste this into a terminal instead of running in here."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T23:58:17.693Z"
    }
   },
   "source": [
    "!python transformers/examples/language-modeling/run_language_modeling.py \\\n",
    "--output_dir gpt2_distil_output \\\n",
    "--model_type gpt2 \\\n",
    "--model_name_or_path \"data/modeling/gpt2_distil_model/\" \\\n",
    "--do_train \\\n",
    "--train_data_file \"data/scraped/name_desc_nlp_ready_train.txt\" \\\n",
    "--do_eval \\\n",
    "--eval_data_file \"data/scraped/name_desc_nlp_ready_test.txt\" \\\n",
    "--per_gpu_train_batch_size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python transformers/examples/language-modeling/run_language_modeling.py \\\n",
    "--output_dir gpt2_distil_output \\\n",
    "--model_type gpt2 \\\n",
    "--model_name_or_path \"data/modeling/gpt2_distil_model/\" \\\n",
    "--do_train \\\n",
    "--train_data_file \"data/scraped/name_desc_nlp_ready_train.txt\" \\\n",
    "--do_eval \\\n",
    "--eval_data_file \"data/scraped/name_desc_nlp_ready_test.txt\" \\\n",
    "--per_gpu_train_batch_size 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python transformers/examples/language-modeling/run_language_modeling.py --output_dir gpt2_xl_output --model_type gpt2 --model_name_or_path \"data/modeling/gpt2_xl_model/\" --do_train --train_data_file \"data/scraped/name_desc_nlp_ready_train.txt\" --do_eval --eval_data_file \"data/scraped/name_desc_nlp_ready_test.txt\" --per_gpu_train_batch_size 1 --evaluate_during_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T18:19:05.452801Z",
     "start_time": "2020-08-19T18:19:05.439799Z"
    }
   },
   "source": [
    "### Find unknown tokens in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T18:11:30.771860Z",
     "start_time": "2020-08-19T18:11:30.321830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125787, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('data/scraped/name_desc_nlp_ready.txt', sep='\\t', header=None)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T18:17:45.820741Z",
     "start_time": "2020-08-19T18:17:20.019715Z"
    }
   },
   "outputs": [],
   "source": [
    "total_tokens = 0\n",
    "total_unknown_tokens = 0\n",
    "for ix, row in dataset.iterrows():\n",
    "  #print(\"-\"*50)\n",
    "  #print(row[2])\n",
    "  tokenized_row = tokenizer.encode(row[2])\n",
    "  #print(tokenized_row)\n",
    "  total_tokens += len(tokenized_row)\n",
    "  total_unknown_tokens += tokenized_row.count(50256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T18:19:38.320331Z",
     "start_time": "2020-08-19T18:19:38.312331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(total_unknown_tokens / total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare GPT2 Models from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:02:34.055136Z",
     "start_time": "2020-08-19T20:02:34.041134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 81.91M\n"
     ]
    }
   ],
   "source": [
    "gpt2_distilled = transformers.AutoModelForCausalLM.from_pretrained('distilgpt2')\n",
    "print(f\"Total parameters: {gpt2_distilled.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:02:34.009132Z",
     "start_time": "2020-08-19T20:02:33.994136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 124.44M\n"
     ]
    }
   ],
   "source": [
    "gpt2 = transformers.AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "print(f\"Total parameters: {gpt2.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T19:56:40.070221Z",
     "start_time": "2020-08-19T19:56:40.064220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 354.82M\n"
     ]
    }
   ],
   "source": [
    "gpt2_medium = transformers.AutoModelForCausalLM.from_pretrained('gpt2-medium')\n",
    "print(f\"Total parameters: {gpt2_medium.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:02:34.102133Z",
     "start_time": "2020-08-19T20:02:34.088135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 774.03M\n"
     ]
    }
   ],
   "source": [
    "gpt2_large = transformers.AutoModelForCausalLM.from_pretrained('gpt2-large')\n",
    "print(f\"Total parameters: {gpt2_large.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:02:41.110326Z",
     "start_time": "2020-08-19T20:02:41.100294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 1557.61M\n"
     ]
    }
   ],
   "source": [
    "gpt2_xl = transformers.AutoModelForCausalLM.from_pretrained('gpt2-xl')\n",
    "print(f\"Total parameters: {gpt2_xl.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T20:22:13.129103Z",
     "start_time": "2020-08-19T20:22:13.111102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.285714285714286"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1500/350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
