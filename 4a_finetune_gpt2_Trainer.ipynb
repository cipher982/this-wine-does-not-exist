{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T23:26:38.364389Z",
     "start_time": "2021-01-21T23:26:32.984151Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=wine_gpt2_Trainer_42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "wandb: Currently logged in as: cipher982 (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.14<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">vocal-gorge-44</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/cipher982/wine_gpt2_Trainer_42\" target=\"_blank\">https://wandb.ai/cipher982/wine_gpt2_Trainer_42</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/cipher982/wine_gpt2_Trainer_42/runs/2effq7cm\" target=\"_blank\">https://wandb.ai/cipher982/wine_gpt2_Trainer_42/runs/2effq7cm</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\david\\Documents\\github\\this-wine-does-not-exist\\wandb\\run-20210121_182636-2effq7cm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "transformers version: 4.2.1\n",
      "PyTorch version: 1.7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "#import deepspeed\n",
    "#import mpi4py\n",
    "#import pandas\n",
    "import torch\n",
    "import transformers\n",
    "import wandb\n",
    "\n",
    "%env WANDB_PROJECT=wine_gpt2_Trainer_42\n",
    "\n",
    "#wandb.login(anonymous='never', key=\"222a37baaf0c1b0d1499ec003e5c2fe49f97b107\")\n",
    "wandb.init()\n",
    "#wandb.watch(log='all')\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(f\"transformers version: {transformers.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T23:26:38.488308Z",
     "start_time": "2021-01-21T23:26:38.475308Z"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'gpt2-medium'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-21T23:27:15.977434Z",
     "start_time": "2021-01-21T23:27:15.359138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n",
      "50264\n",
      "Created tokenizer\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(len(tokenizer))\n",
    "\n",
    "tokenizer.add_special_tokens(\n",
    "  {'eos_token':'<|startoftext|>',\n",
    "   'bos_token':'<|startoftext|>'\n",
    "  }\n",
    ")\n",
    "tokenizer.add_tokens(['[prompt]','[response]','[category_1]',\n",
    "                      '[category_2]','[origin]','[description]',\n",
    "                      '<|endoftext|>'])\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenizer.save_pretrained(\"data/modeling/trainer_42/\")\n",
    "\n",
    "print(len(tokenizer))\n",
    "print(\"Created tokenizer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wineDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, encodings):\n",
    "    self.encodings = encodings\n",
    "            \n",
    "  def __len__(self):\n",
    "    return len(self.encodings['input_ids'])\n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    item['labels'] = item['input_ids']\n",
    "    return item\n",
    "\n",
    "  \n",
    "with open('data/scraped/name_desc_nlp_ready_train.txt', 'r', encoding='utf8') as file:\n",
    "    wines_raw_train = file.read().splitlines()\n",
    "with open('data/scraped/name_desc_nlp_ready_test.txt', 'r', encoding='utf8') as file:\n",
    "    wines_raw_test = file.read().splitlines()\n",
    "print(\"Loaded dataset\")\n",
    "\n",
    "#wines_raw_train, wines_raw_test = train_test_split(wines_raw,test_size=0.2)\n",
    "\n",
    "#wine_encodings_train = tokenizer(wines_raw_train, max_length=200, truncation=True, padding=True)\n",
    "wine_encodings_test = tokenizer(wines_raw_test, max_length=200, truncation=True, padding=True)\n",
    "print(\"Encoded dataset\")\n",
    "\n",
    "#wine_dataset_train = wineDataset(wine_encodings_train)\n",
    "wine_dataset_test = wineDataset(wine_encodings_test)\n",
    "print(\"Created PyTorch DataSet\")\n",
    "\n",
    "#train_loader = torch.utils.data.DataLoader(wine_dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "#model.to('cuda')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "print(f\"model parameters: {model.num_parameters():,}\")\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir=\"data/modeling/trainer_42/\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    #deepspeed='data/ds_config.json'\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=wine_dataset_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Before Modifications:\n",
    "\n",
    "distilgpt2 - single batch = 5.8GB - (2.1 at idle) = 3.7GB \n",
    "distilgpt2 - 2 batch = 5.5GB - (2.1 at idle) = 3.7GB \n",
    "distilgpt2 - 4 batch = 5.5GB - (2.1 at idle) = 3.7GB same??\n",
    "distilgpt2 - 8 batch = 6.5GB - (2.1 at idle) = \n",
    "distilgpt2 - 20 batch = 10.4GB - (2.1 at idle) = 8.3GB\n",
    "gpt2-small - 16 batch = oom - (2.1 at idle)\n",
    "gpt2-small - 12 batch = 10.1 - (2.1 at idle) = 8GB\n",
    "gpt2-medium - 2 batch = 9.1 - (2.1 at idle) = 7GB\n",
    "gpt2-medium - 3 batch = 10.4 - (2.1 at idle) = 8.3GB\n",
    "gpt2-large - 1 batch == oom\n",
    "\n",
    "fp16\n",
    "gpt2-medium - 3 batch = 10.4GB - (2.1 at idle) = 8.3GB\n",
    "\n",
    "deepspeed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
