{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Input text [4733481] Dark garnet in color, the 2013 HALL Napa Valley Ca\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[116, 101, 100,  32, 101, 118, 101, 114,  32, 115]]), array([[[101],\n",
       "         [100],\n",
       "         [ 32],\n",
       "         [101],\n",
       "         [118],\n",
       "         [101],\n",
       "         [114],\n",
       "         [ 32],\n",
       "         [115],\n",
       "         [105]]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = 'data/pickles/descriptions.pickle'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def transform(txt, pad_to=None):\n",
    "    # drop any non-ascii characters\n",
    "    output = np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n",
    "    if pad_to is not None:\n",
    "        output = output[:pad_to]\n",
    "        output = np.concatenate([\n",
    "            np.zeros([pad_to - len(txt)], dtype=np.int32),\n",
    "            output\n",
    "        ])\n",
    "    return output\n",
    "\n",
    "def training_generator(seq_len=100, batch_size=1024):\n",
    "    \"\"\"A generator yields (source, target) arrays for training.\"\"\"\n",
    "    names_raw, descs_raw = pd.read_pickle(DATA_PATH)\n",
    "    txt = '\\n'.join(descs_raw)\n",
    "\n",
    "    tf.logging.info('Input text [%d] %s', len(txt), txt[:50])\n",
    "    source = transform(txt)\n",
    "    while True:\n",
    "        offsets = np.random.randint(0, len(source) - seq_len, batch_size)\n",
    "\n",
    "        # Our model uses sparse crossentropy loss, but Keras requires labels\n",
    "        # to have the same rank as the input logits.  We add an empty final\n",
    "        # dimension to account for this.\n",
    "        yield (\n",
    "            np.stack([source[idx:idx + seq_len] for idx in offsets]),\n",
    "            np.expand_dims(\n",
    "                np.stack([source[idx + 1:idx + seq_len + 1] for idx in offsets]), \n",
    "                -1),\n",
    "        )\n",
    "\n",
    "six.next(training_generator(seq_len=10, batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 512\n",
    "\n",
    "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
    "    \"\"\"Language model: predict the next word given the current word.\"\"\"\n",
    "    source = tf.keras.Input(\n",
    "        name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
    "\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
    "    lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
    "    lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
    "    #drop_1 = tf.keras.layers.Dropout(0.2)\n",
    "    predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n",
    "    model = tf.keras.Model(inputs=[source], outputs=[predicted_char])\n",
    "    #model = tf.keras.utils.multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.train.RMSPropOptimizer(learning_rate=0.01),\n",
    "        #optimizer=tf.keras.optimizers.RMSprop(lr=0.01),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "training_model = lstm_model(seq_len=100, batch_size=1024, stateful=False)\n",
    "#training_model.load_weights('model_small_chkpt.h5', by_name=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint('data/models_weights/model_char_DESCS_chkpt_old.h5', \n",
    "                             monitor='sparse_categorical_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')\n",
    "early_stopping = EarlyStopping(monitor='sparse_categorical_accuracy',\n",
    "                               patience=3,\n",
    "                               mode='max')\n",
    "callbacks_list = [checkpoint,early_stopping]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#training_model.load_weights('data/models_weights/model_char_DESCS_weights.h5')\n",
    "\n",
    "training_model.fit_generator(\n",
    "    training_generator(seq_len=100, batch_size=1024),\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    callbacks = callbacks_list\n",
    "    )\n",
    "\n",
    "training_model.save_weights('data/models_weights/model_char_DESCS_weights_old.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seed (InputLayer)            (1024, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (1024, 100, 512)          131072    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (1024, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1024, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (1024, 100, 256)          131328    \n",
      "=================================================================\n",
      "Total params: 4,460,800\n",
      "Trainable params: 4,460,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_model.load_weights('data/models_weights/model_char_DESCS_chkpt_old.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_acc = training_model.history.history['sparse_categorical_accuracy']\n",
    "plt.figure(dpi=150)\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.plot(range(len(training_acc)),  training_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BASIC wine DESCRIPTION list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 0\n",
      "\n",
      "\n",
      "Y. The story is best known for its award-winnine experienced from all other vintage Champagne to unfold. As orphorng, Garnacha, Toro, Alivation that connoisseurs, as is the marriage of dried blynd sites, the wine is fruity, there is pleasant flavors of  plum fruits, jammavors, and a tea-leaf as thewine wild strawberry and raspberry flavors with a t\n",
      "\n",
      "PREDICTION 1\n",
      "\n",
      "\n",
      "Y. The vineyards are nestled about this Pinot noir and Cabernet Sauvignon and 2001. Laura blend offers complex nuances of apple flavors to a rivetting potential, intense depth and depth together toward almost hillside parcel above the earth and thanks to who introduce bears son, whole cluster (Armanding 200-acre estate located in Clavender, the REE\n",
      "\n",
      "PREDICTION 2\n",
      "\n",
      "\n",
      "Y.\n",
      "This bold Andalt was from his honored tradition and innovation in New Zealand winemaking. Villa naturally in the Napa Valley and intesticing bold growing conditions.\n",
      "\n",
      "Shrounded by the 92-acre Tigson to whom bust to Napa Valley, and provides the first new post-prohibits planted alcohol, and an easy-drinking, licorice, as watery, yet balanced by c\n",
      "\n",
      "PREDICTION 3\n",
      "\n",
      "\n",
      "Y. If you feed gave it touches of ripe pear, melon, and grapefruit, along with notes of pineapple, baked pear and delicious.\n",
      "A ruby red color with ruby hints. On the nose, ripe Spink black fruits, bramble, rose petal flowers, and tropical fruit aromas.\n",
      "Jainquest Côtes de Provence vines around 60 years old. Grilled seafood, sushains all the way to a\n",
      "\n",
      "PREDICTION 4\n",
      "\n",
      "\n",
      "Y. Tasty, bright fruit supporting to take a little brothers to milly attribute those, we are from the ground up. Today, the vineyards filled and cling cling in Lichine that invites their past few years he caltem of NOw to be took note (Beak and musts oldest Mondavi Winery in the 70s - Jz- minutes - a lingering mouthfeel tanks!\n",
      "\n",
      "Lajoro AlboN, founde\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5\n",
    "PREDICT_LEN = 350\n",
    "\n",
    "# Keras requires the batch size be specified ahead of time for stateful models.\n",
    "# We use a sequence length of 1, as we will be feeding in one character at a \n",
    "# time and predicting the next character.\n",
    "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
    "prediction_model.load_weights('data/models_weights/model_char_DESCS_chkpt_old.h5')\n",
    "\n",
    "# We seed the model with our initial string, copied BATCH_SIZE times\n",
    "\n",
    "seed_txt = 'This wine tastes like '\n",
    "seed_txt = ''.join(random.choices(string.ascii_uppercase + string.digits, k=20))\n",
    "seed = transform(seed_txt)\n",
    "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
    "\n",
    "# First, run the seed forward to prime the state of the model.\n",
    "prediction_model.reset_states()\n",
    "for i in range(len(seed_txt) - 1):\n",
    "    prediction_model.predict(seed[:, i:i + 1])\n",
    "\n",
    "# Now we can accumulate predictions!\n",
    "predictions = [seed[:, -1:]]\n",
    "for i in range(PREDICT_LEN):\n",
    "    last_word = predictions[-1]\n",
    "    next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
    "  \n",
    "  # sample from our output distribution\n",
    "    next_idx = [\n",
    "        np.random.choice(256, p=next_probits[i])\n",
    "        for i in range(BATCH_SIZE)\n",
    "    ]\n",
    "    predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
    "    \n",
    "for i in range(BATCH_SIZE):\n",
    "    print('PREDICTION %d\\n\\n' % i)\n",
    "    p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
    "    generated = ''.join([chr(c) for c in p])\n",
    "    print(generated)\n",
    "    print()\n",
    "    assert len(generated) == PREDICT_LEN, 'Generated text too short'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BIG fake wine DESCRIPTION list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 36)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                                       | 0/100 [00:00<?, ?it/s]\n",
      "\n",
      "  1%|▋                                                              | 1/100 [00:06<10:19,  6.25s/it]\n",
      "\n",
      "  2%|█▎                                                             | 2/100 [00:07<07:56,  4.86s/it]\n",
      "\n",
      "  3%|█▉                                                             | 3/100 [00:09<06:17,  3.89s/it]\n",
      "\n",
      "  4%|██▌                                                            | 4/100 [00:11<05:08,  3.22s/it]\n",
      "\n",
      "  5%|███▏                                                           | 5/100 [00:12<04:21,  2.75s/it]\n",
      "\n",
      "  6%|███▊                                                           | 6/100 [00:14<03:49,  2.44s/it]\n",
      "\n",
      "  7%|████▍                                                          | 7/100 [00:16<03:24,  2.20s/it]\n",
      "\n",
      "  8%|█████                                                          | 8/100 [00:17<03:07,  2.03s/it]\n",
      "\n",
      "  9%|█████▋                                                         | 9/100 [00:19<02:54,  1.92s/it]\n",
      "\n",
      " 10%|██████▏                                                       | 10/100 [00:21<02:44,  1.83s/it]\n",
      "\n",
      " 11%|██████▊                                                       | 11/100 [00:22<02:39,  1.79s/it]\n",
      "\n",
      " 12%|███████▍                                                      | 12/100 [00:24<02:33,  1.74s/it]\n",
      "\n",
      " 13%|████████                                                      | 13/100 [00:26<02:28,  1.70s/it]\n",
      "\n",
      " 14%|████████▋                                                     | 14/100 [00:27<02:26,  1.70s/it]\n",
      "\n",
      " 15%|█████████▎                                                    | 15/100 [00:29<02:22,  1.68s/it]\n",
      "\n",
      " 16%|█████████▉                                                    | 16/100 [00:31<02:21,  1.68s/it]\n",
      "\n",
      " 17%|██████████▌                                                   | 17/100 [00:32<02:17,  1.66s/it]\n",
      "\n",
      " 18%|███████████▏                                                  | 18/100 [00:34<02:15,  1.65s/it]\n",
      "\n",
      " 19%|███████████▊                                                  | 19/100 [00:35<02:14,  1.66s/it]\n",
      "\n",
      " 20%|████████████▍                                                 | 20/100 [00:37<02:12,  1.66s/it]\n",
      "\n",
      " 21%|█████████████                                                 | 21/100 [00:39<02:11,  1.67s/it]\n",
      "\n",
      " 22%|█████████████▋                                                | 22/100 [00:40<02:08,  1.65s/it]\n",
      "\n",
      " 23%|██████████████▎                                               | 23/100 [00:42<02:05,  1.63s/it]\n",
      "\n",
      " 24%|██████████████▉                                               | 24/100 [00:44<02:04,  1.64s/it]\n",
      "\n",
      " 25%|███████████████▌                                              | 25/100 [00:45<02:01,  1.62s/it]\n",
      "\n",
      " 26%|████████████████                                              | 26/100 [00:47<01:59,  1.62s/it]\n",
      "\n",
      " 27%|████████████████▋                                             | 27/100 [00:48<01:58,  1.62s/it]\n",
      "\n",
      " 28%|█████████████████▎                                            | 28/100 [00:50<01:57,  1.63s/it]\n",
      "\n",
      " 29%|█████████████████▉                                            | 29/100 [00:52<01:55,  1.62s/it]\n",
      "\n",
      " 30%|██████████████████▌                                           | 30/100 [00:53<01:53,  1.62s/it]\n",
      "\n",
      " 31%|███████████████████▏                                          | 31/100 [00:55<01:52,  1.63s/it]\n",
      "\n",
      " 32%|███████████████████▊                                          | 32/100 [00:57<01:51,  1.64s/it]\n",
      "\n",
      " 33%|████████████████████▍                                         | 33/100 [00:58<01:50,  1.65s/it]\n",
      "\n",
      " 34%|█████████████████████                                         | 34/100 [01:00<01:49,  1.65s/it]\n",
      "\n",
      " 35%|█████████████████████▋                                        | 35/100 [01:02<01:48,  1.67s/it]\n",
      "\n",
      " 36%|██████████████████████▎                                       | 36/100 [01:03<01:46,  1.67s/it]\n",
      "\n",
      " 37%|██████████████████████▉                                       | 37/100 [01:05<01:44,  1.66s/it]\n",
      "\n",
      " 38%|███████████████████████▌                                      | 38/100 [01:07<01:42,  1.66s/it]\n",
      "\n",
      " 39%|████████████████████████▏                                     | 39/100 [01:08<01:40,  1.64s/it]\n",
      "\n",
      " 40%|████████████████████████▊                                     | 40/100 [01:10<01:37,  1.63s/it]\n",
      "\n",
      " 41%|█████████████████████████▍                                    | 41/100 [01:12<01:36,  1.64s/it]\n",
      "\n",
      " 42%|██████████████████████████                                    | 42/100 [01:13<01:35,  1.64s/it]\n",
      "\n",
      " 43%|██████████████████████████▋                                   | 43/100 [01:15<01:34,  1.65s/it]\n",
      "\n",
      " 44%|███████████████████████████▎                                  | 44/100 [01:17<01:32,  1.65s/it]\n",
      "\n",
      " 45%|███████████████████████████▉                                  | 45/100 [01:18<01:30,  1.64s/it]\n",
      "\n",
      " 46%|████████████████████████████▌                                 | 46/100 [01:20<01:28,  1.64s/it]\n",
      "\n",
      " 47%|█████████████████████████████▏                                | 47/100 [01:21<01:28,  1.66s/it]\n",
      "\n",
      " 48%|█████████████████████████████▊                                | 48/100 [01:23<01:26,  1.66s/it]\n",
      "\n",
      " 49%|██████████████████████████████▍                               | 49/100 [01:25<01:24,  1.66s/it]\n",
      "\n",
      " 50%|███████████████████████████████                               | 50/100 [01:26<01:21,  1.64s/it]\n",
      "\n",
      " 51%|███████████████████████████████▌                              | 51/100 [01:28<01:20,  1.64s/it]\n",
      "\n",
      " 52%|████████████████████████████████▏                             | 52/100 [01:30<01:19,  1.65s/it]\n",
      "\n",
      " 53%|████████████████████████████████▊                             | 53/100 [01:31<01:17,  1.64s/it]\n",
      "\n",
      " 54%|█████████████████████████████████▍                            | 54/100 [01:33<01:16,  1.66s/it]\n",
      "\n",
      " 55%|██████████████████████████████████                            | 55/100 [01:35<01:14,  1.65s/it]\n",
      "\n",
      " 56%|██████████████████████████████████▋                           | 56/100 [01:36<01:12,  1.66s/it]\n",
      "\n",
      " 57%|███████████████████████████████████▎                          | 57/100 [01:38<01:10,  1.64s/it]\n",
      "\n",
      " 58%|███████████████████████████████████▉                          | 58/100 [01:40<01:08,  1.64s/it]\n",
      "\n",
      " 59%|████████████████████████████████████▌                         | 59/100 [01:41<01:08,  1.66s/it]\n",
      "\n",
      " 60%|█████████████████████████████████████▏                        | 60/100 [01:43<01:06,  1.66s/it]\n",
      "\n",
      " 61%|█████████████████████████████████████▊                        | 61/100 [01:45<01:04,  1.66s/it]\n",
      "\n",
      " 62%|██████████████████████████████████████▍                       | 62/100 [01:46<01:02,  1.65s/it]\n",
      "\n",
      " 63%|███████████████████████████████████████                       | 63/100 [01:48<01:00,  1.65s/it]\n",
      "\n",
      " 64%|███████████████████████████████████████▋                      | 64/100 [01:50<00:59,  1.64s/it]\n",
      "\n",
      " 65%|████████████████████████████████████████▎                     | 65/100 [01:51<00:57,  1.65s/it]\n",
      "\n",
      " 66%|████████████████████████████████████████▉                     | 66/100 [01:53<00:56,  1.65s/it]\n",
      "\n",
      " 67%|█████████████████████████████████████████▌                    | 67/100 [01:54<00:54,  1.64s/it]\n",
      "\n",
      " 68%|██████████████████████████████████████████▏                   | 68/100 [01:56<00:52,  1.64s/it]\n",
      "\n",
      " 69%|██████████████████████████████████████████▊                   | 69/100 [01:58<00:50,  1.64s/it]\n",
      "\n",
      " 70%|███████████████████████████████████████████▍                  | 70/100 [01:59<00:49,  1.64s/it]\n",
      "\n",
      " 71%|████████████████████████████████████████████                  | 71/100 [02:01<00:47,  1.64s/it]\n",
      "\n",
      " 72%|████████████████████████████████████████████▋                 | 72/100 [02:03<00:46,  1.64s/it]\n",
      "\n",
      " 73%|█████████████████████████████████████████████▎                | 73/100 [02:04<00:44,  1.64s/it]\n",
      "\n",
      " 74%|█████████████████████████████████████████████▉                | 74/100 [02:06<00:42,  1.63s/it]\n",
      "\n",
      " 75%|██████████████████████████████████████████████▌               | 75/100 [02:07<00:40,  1.62s/it]\n",
      "\n",
      " 76%|███████████████████████████████████████████████               | 76/100 [02:09<00:39,  1.65s/it]\n",
      "\n",
      " 77%|███████████████████████████████████████████████▋              | 77/100 [02:11<00:37,  1.65s/it]\n",
      "\n",
      " 78%|████████████████████████████████████████████████▎             | 78/100 [02:12<00:36,  1.64s/it]\n",
      "\n",
      " 79%|████████████████████████████████████████████████▉             | 79/100 [02:14<00:34,  1.66s/it]\n",
      "\n",
      " 80%|█████████████████████████████████████████████████▌            | 80/100 [02:16<00:33,  1.67s/it]\n",
      "\n",
      " 81%|██████████████████████████████████████████████████▏           | 81/100 [02:18<00:31,  1.67s/it]\n",
      "\n",
      " 82%|██████████████████████████████████████████████████▊           | 82/100 [02:19<00:30,  1.68s/it]\n",
      "\n",
      " 83%|███████████████████████████████████████████████████▍          | 83/100 [02:21<00:28,  1.67s/it]\n",
      "\n",
      " 84%|████████████████████████████████████████████████████          | 84/100 [02:23<00:26,  1.68s/it]\n",
      "\n",
      " 85%|████████████████████████████████████████████████████▋         | 85/100 [02:24<00:24,  1.67s/it]\n",
      "\n",
      " 86%|█████████████████████████████████████████████████████▎        | 86/100 [02:26<00:23,  1.67s/it]\n",
      "\n",
      " 87%|█████████████████████████████████████████████████████▉        | 87/100 [02:28<00:21,  1.68s/it]\n",
      "\n",
      " 88%|██████████████████████████████████████████████████████▌       | 88/100 [02:29<00:20,  1.67s/it]\n",
      "\n",
      " 89%|███████████████████████████████████████████████████████▏      | 89/100 [02:31<00:18,  1.66s/it]\n",
      "\n",
      " 90%|███████████████████████████████████████████████████████▊      | 90/100 [02:32<00:16,  1.64s/it]\n",
      "\n",
      " 91%|████████████████████████████████████████████████████████▍     | 91/100 [02:34<00:14,  1.63s/it]\n",
      "\n",
      " 92%|█████████████████████████████████████████████████████████     | 92/100 [02:36<00:13,  1.65s/it]\n",
      "\n",
      " 93%|█████████████████████████████████████████████████████████▋    | 93/100 [02:37<00:11,  1.64s/it]\n",
      "\n",
      " 94%|██████████████████████████████████████████████████████████▎   | 94/100 [02:39<00:09,  1.63s/it]\n",
      "\n",
      " 95%|██████████████████████████████████████████████████████████▉   | 95/100 [02:41<00:08,  1.63s/it]\n",
      "\n",
      " 96%|███████████████████████████████████████████████████████████▌  | 96/100 [02:42<00:06,  1.64s/it]\n",
      "\n",
      " 97%|████████████████████████████████████████████████████████████▏ | 97/100 [02:44<00:04,  1.63s/it]\n",
      "\n",
      " 98%|████████████████████████████████████████████████████████████▊ | 98/100 [02:46<00:03,  1.64s/it]\n",
      "\n",
      " 99%|█████████████████████████████████████████████████████████████▍| 99/100 [02:47<00:01,  1.65s/it]\n",
      "\n",
      "100%|█████████████████████████████████████████████████████████████| 100/100 [02:49<00:00,  1.64s/it]"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "PREDICT_LEN = 600\n",
    "N_PREDICTIONS = 100\n",
    "\n",
    "# Keras requires the batch size be specified ahead of time for stateful models.\n",
    "# We use a sequence length of 1, as we will be feeding in one character at a \n",
    "# time and predicting the next character.\n",
    "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
    "prediction_model.load_weights('data/models_weights/model_char_DESCS_chkpt_old.h5')\n",
    "\n",
    "predicted_names = pd.read_csv('data/outputs/NAMES_v1.csv')\n",
    "\n",
    "fake_DESC = []\n",
    "for ii in tqdm(range(N_PREDICTIONS)):\n",
    "    # We seed the model with our initial string, copied BATCH_SIZE times\n",
    "    #seed_array = np.zeros(shape=(BATCH_SIZE,))\n",
    "    for i in range(BATCH_SIZE):\n",
    "        seed_txt = predicted_names['name'][ii+i]\n",
    "        seed = transform(seed_txt)\n",
    "        #print(seed.shape)\n",
    "    seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
    "    \n",
    "\n",
    "    # First, run the seed forward to prime the state of the model.\n",
    "    prediction_model.reset_states()\n",
    "    for i in range(len(seed_txt) - 1):\n",
    "        prediction_model.predict(seed[:, i:i + 1])\n",
    "\n",
    "    # Now we can accumulate predictions!\n",
    "    predictions = [seed[:, -1:]]\n",
    "    for i in range(PREDICT_LEN):\n",
    "        last_word = predictions[-1]\n",
    "        next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
    "\n",
    "      # sample from our output distribution\n",
    "        next_idx = [\n",
    "            np.random.choice(256, p=next_probits[i])\n",
    "            for i in range(BATCH_SIZE)\n",
    "        ]\n",
    "        predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        #print('PREDICTION %d\\n\\n' % i)\n",
    "        p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
    "        generated = ''.join([chr(c) for c in p])\n",
    "        fake_DESC.append(generated)\n",
    "        #print(generated)\n",
    "        #print()\n",
    "        gen_list = generated.split('.')[1:-1]\n",
    "        gen_conc = ' '.join(gen_list) + '.'\n",
    "        fake_DESC.append(gen_conc)\n",
    "        #print(gen_conc)\n",
    "        #for item in gen_list:\n",
    "        #    fake_DESC.append(item.strip()+'.')\n",
    "        #assert len(generated) == PREDICT_LEN, 'Generated text too short'\n",
    "pd.DataFrame(fake_DESC, columns=['Description'])\\\n",
    "    .to_csv('data/outputs/DESC_v1_1.csv', index_label=False, index=False, sep='|')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filepath = 'data/fake_desc_scores_v1.csv'\n",
    "pd.Series(fake_scores).to_csv(filepath)\n",
    "fake_DESC = pd.read_csv(filepath, names=['Name','Score'])\n",
    "fake_DESC = fake_DESC.loc[fake_DESC['Name'].str.len() > 20]\n",
    "len(fake_DESC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.title('Disitribution of fake wine descs to real ones')\n",
    "plt.hist(fake_DESC['Score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "real_names, descs_raw = pd.read_pickle(DATA_PATH)\n",
    "fake_scores = {}\n",
    "for f_name in tqdm(fake_names):\n",
    "    max_score = 0.0\n",
    "    for r_name in descs_raw:\n",
    "        if similar(f_name,r_name) > max_score:\n",
    "            max_score = similar(f_name,r_name)\n",
    "    fake_scores[f_name] = max_score\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "PREDICT_LEN = 250\n",
    "\n",
    "# Keras requires the batch size be specified ahead of time for stateful models.\n",
    "# We use a sequence length of 1, as we will be feeding in one character at a \n",
    "# time and predicting the next character.\n",
    "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
    "prediction_model.load_weights('/tmp/bard.h5')\n",
    "\n",
    "# We seed the model with our initial string, copied BATCH_SIZE times\n",
    "\n",
    "seed_txt = 'Looks it not like the king?  Verily, we must go! '\n",
    "seed = transform(seed_txt)\n",
    "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
    "\n",
    "# First, run the seed forward to prime the state of the model.\n",
    "prediction_model.reset_states()\n",
    "for i in range(len(seed_txt) - 1):\n",
    "    prediction_model.predict(seed[:, i:i + 1])\n",
    "\n",
    "# Now we can accumulate predictions!\n",
    "predictions = [seed[:, -1:]]\n",
    "for i in range(PREDICT_LEN):\n",
    "    last_word = predictions[-1]\n",
    "    next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
    "  \n",
    "  # sample from our output distribution\n",
    "    next_idx = [\n",
    "        np.random.choice(256, p=next_probits[i])\n",
    "        for i in range(BATCH_SIZE)\n",
    "    ]\n",
    "    predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
    "    \n",
    "for i in range(BATCH_SIZE):\n",
    "    print('PREDICTION %d\\n\\n' % i)\n",
    "    p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
    "    generated = ''.join([chr(c) for c in p])\n",
    "    print(generated)\n",
    "    print()\n",
    "    assert len(generated) == PREDICT_LEN, 'Generated text too short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
