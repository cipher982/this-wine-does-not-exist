{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import pandas\n",
    "import torch\n",
    "import transformers\n",
    "import wandb\n",
    "\n",
    "%env WANDB_WATCH=all\n",
    "%env WANDB_PROJECT=wine_gpt2_Trainer_42\n",
    "\n",
    "#wandb.login(anonymous='never', key=\"222a37baaf0c1b0d1499ec003e5c2fe49f97b107\")\n",
    "wandb.init()\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(f\"transformers version: {transformers.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add tokens from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained('distilgpt2')\n",
    "print(tokenizer.vocab_size)\n",
    "\n",
    "tokenizer.add_special_tokens(\n",
    "  {'eos_token':'<|startoftext|>',\n",
    "   'bos_token':'<|startoftext|>'\n",
    "  }\n",
    ")\n",
    "tokenizer.add_tokens(['[prompt]','[response]','[category_1]',\n",
    "                      '[category_2]','[origin]','[description]',\n",
    "                      '<|endoftext|>'])\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenizer.save_pretrained(\"data/modeling/trainer_42/\")\n",
    "\n",
    "print(tokenizer.vocab_size)\n",
    "print(\"Created tokenizer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2TokenizerFast\n",
    "\n",
    "config = GPT2Config()\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"data/modeling/trainer_42/\")\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2')\n",
    "print(f\"model parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"data/scraped/name_desc_nlp_ready_test.txt\",\n",
    "    block_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "  tokenizer=tokenizer, \n",
    "  mlm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"data/modeling/trainer_42/\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GPT2 model to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModelWithLMHead.from_pretrained('gpt2-xl')\n",
    "print(f\"Total parameters: {model.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('data/modeling/gpt2_xl_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the method in which Jupyter processes shell commands it won't show STDOUT live, only outputting once the run is finished. So I prefer to just paste this into a terminal instead of running in here."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-18T23:58:17.693Z"
    }
   },
   "source": [
    "!python transformers/examples/language-modeling/run_language_modeling.py \\\n",
    "--output_dir gpt2_distil_output \\\n",
    "--model_type gpt2 \\\n",
    "--model_name_or_path \"data/modeling/gpt2_distil_model/\" \\\n",
    "--do_train \\\n",
    "--train_data_file \"data/scraped/name_desc_nlp_ready_train.txt\" \\\n",
    "--do_eval \\\n",
    "--eval_data_file \"data/scraped/name_desc_nlp_ready_test.txt\" \\\n",
    "--per_gpu_train_batch_size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python transformers/examples/language-modeling/run_language_modeling.py \\\n",
    "--output_dir gpt2_distil_output \\\n",
    "--model_type gpt2 \\\n",
    "--model_name_or_path \"data/modeling/gpt2_distil_model/\" \\\n",
    "--do_train \\\n",
    "--train_data_file \"data/scraped/name_desc_nlp_ready_train.txt\" \\\n",
    "--do_eval \\\n",
    "--eval_data_file \"data/scraped/name_desc_nlp_ready_test.txt\" \\\n",
    "--per_gpu_train_batch_size 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python transformers/examples/language-modeling/run_language_modeling.py --output_dir gpt2_xl_output --model_type gpt2 --model_name_or_path \"data/modeling/gpt2_xl_model/\" --do_train --train_data_file \"data/scraped/name_desc_nlp_ready_train.txt\" --do_eval --eval_data_file \"data/scraped/name_desc_nlp_ready_test.txt\" --per_gpu_train_batch_size 1 --evaluate_during_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T18:19:05.452801Z",
     "start_time": "2020-08-19T18:19:05.439799Z"
    }
   },
   "source": [
    "### Find unknown tokens in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('data/scraped/name_desc_nlp_ready.txt', sep='\\t', header=None)\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = 0\n",
    "total_unknown_tokens = 0\n",
    "for ix, row in dataset.iterrows():\n",
    "  #print(\"-\"*50)\n",
    "  #print(row[2])\n",
    "  tokenized_row = tokenizer.encode(row[2])\n",
    "  #print(tokenized_row)\n",
    "  total_tokens += len(tokenized_row)\n",
    "  total_unknown_tokens += tokenized_row.count(50256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_unknown_tokens / total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare GPT2 Models from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_distilled = transformers.AutoModelForCausalLM.from_pretrained('distilgpt2')\n",
    "print(f\"Total parameters: {gpt2_distilled.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = transformers.AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "print(f\"Total parameters: {gpt2.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_medium = transformers.AutoModelForCausalLM.from_pretrained('gpt2-medium')\n",
    "print(f\"Total parameters: {gpt2_medium.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_large = transformers.AutoModelForCausalLM.from_pretrained('gpt2-large')\n",
    "print(f\"Total parameters: {gpt2_large.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_xl = transformers.AutoModelForCausalLM.from_pretrained('gpt2-xl')\n",
    "print(f\"Total parameters: {gpt2_xl.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1500/350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
