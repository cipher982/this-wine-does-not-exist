{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Input text [4733481] Dark garnet in color, the 2013 HALL Napa Valley Ca\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[114, 114, 105, 101, 115,  32,  97, 110, 100,  32]]), array([[[114],\n",
       "         [105],\n",
       "         [101],\n",
       "         [115],\n",
       "         [ 32],\n",
       "         [ 97],\n",
       "         [110],\n",
       "         [100],\n",
       "         [ 32],\n",
       "         [ 99]]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = 'data/pickles/descriptions.pickle'\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def transform(txt, pad_to=None):\n",
    "    # drop any non-ascii characters\n",
    "    output = np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n",
    "    if pad_to is not None:\n",
    "        output = output[:pad_to]\n",
    "        output = np.concatenate([\n",
    "            np.zeros([pad_to - len(txt)], dtype=np.int32),\n",
    "            output\n",
    "        ])\n",
    "    return output\n",
    "\n",
    "def training_generator(seq_len=100, batch_size=1024):\n",
    "    \"\"\"A generator yields (source, target) arrays for training.\"\"\"\n",
    "    names_raw, descs_raw = pd.read_pickle(DATA_PATH)\n",
    "    txt = '\\n'.join(descs_raw)\n",
    "\n",
    "    tf.logging.info('Input text [%d] %s', len(txt), txt[:50])\n",
    "    source = transform(txt)\n",
    "    while True:\n",
    "        offsets = np.random.randint(0, len(source) - seq_len, batch_size)\n",
    "\n",
    "        # Our model uses sparse crossentropy loss, but Keras requires labels\n",
    "        # to have the same rank as the input logits.  We add an empty final\n",
    "        # dimension to account for this.\n",
    "        yield (\n",
    "            np.stack([source[idx:idx + seq_len] for idx in offsets]),\n",
    "            np.expand_dims(\n",
    "                np.stack([source[idx + 1:idx + seq_len + 1] for idx in offsets]), \n",
    "                -1),\n",
    "        )\n",
    "\n",
    "six.next(training_generator(seq_len=10, batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 512\n",
    "\n",
    "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
    "    \"\"\"Language model: predict the next word given the current word.\"\"\"\n",
    "    source = tf.keras.Input(\n",
    "        name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
    "\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
    "    lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
    "    lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
    "    #drop_1 = tf.keras.layers.Dropout(0.2)\n",
    "    predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n",
    "    model = tf.keras.Model(inputs=[source], outputs=[predicted_char])\n",
    "    #model = tf.keras.utils.multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.train.RMSPropOptimizer(learning_rate=0.01),\n",
    "        #optimizer=tf.keras.optimizers.RMSprop(lr=0.01),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "training_model = lstm_model(seq_len=100, batch_size=1024, stateful=False)\n",
    "#training_model.load_weights('model_small_chkpt.h5', by_name=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint('data/models_weights/model_char_DESCS_chkpt_old.h5', \n",
    "                             monitor='sparse_categorical_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')\n",
    "early_stopping = EarlyStopping(monitor='sparse_categorical_accuracy',\n",
    "                               patience=3,\n",
    "                               mode='max')\n",
    "callbacks_list = [checkpoint,early_stopping]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#training_model.load_weights('data/models_weights/model_char_DESCS_weights.h5')\n",
    "\n",
    "training_model.fit_generator(\n",
    "    training_generator(seq_len=100, batch_size=1024),\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    callbacks = callbacks_list\n",
    "    )\n",
    "\n",
    "training_model.save_weights('data/models_weights/model_char_DESCS_weights_old.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seed (InputLayer)            (1024, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (1024, 100, 512)          131072    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (1024, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1024, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (1024, 100, 256)          131328    \n",
      "=================================================================\n",
      "Total params: 4,460,800\n",
      "Trainable params: 4,460,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_model.load_weights('data/models_weights/model_char_DESCS_chkpt_old.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_acc = training_model.history.history['sparse_categorical_accuracy']\n",
    "plt.figure(dpi=150)\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.plot(range(len(training_acc)),  training_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BASIC wine DESCRIPTION list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 0\n",
      "\n",
      "\n",
      "Y. The story is best known for its award-winnine experienced from all other vintage Champagne to unfold. As orphorng, Garnacha, Toro, Alivation that connoisseurs, as is the marriage of dried blynd sites, the wine is fruity, there is pleasant flavors of  plum fruits, jammavors, and a tea-leaf as thewine wild strawberry and raspberry flavors with a t\n",
      "\n",
      "PREDICTION 1\n",
      "\n",
      "\n",
      "Y. The vineyards are nestled about this Pinot noir and Cabernet Sauvignon and 2001. Laura blend offers complex nuances of apple flavors to a rivetting potential, intense depth and depth together toward almost hillside parcel above the earth and thanks to who introduce bears son, whole cluster (Armanding 200-acre estate located in Clavender, the REE\n",
      "\n",
      "PREDICTION 2\n",
      "\n",
      "\n",
      "Y.\n",
      "This bold Andalt was from his honored tradition and innovation in New Zealand winemaking. Villa naturally in the Napa Valley and intesticing bold growing conditions.\n",
      "\n",
      "Shrounded by the 92-acre Tigson to whom bust to Napa Valley, and provides the first new post-prohibits planted alcohol, and an easy-drinking, licorice, as watery, yet balanced by c\n",
      "\n",
      "PREDICTION 3\n",
      "\n",
      "\n",
      "Y. If you feed gave it touches of ripe pear, melon, and grapefruit, along with notes of pineapple, baked pear and delicious.\n",
      "A ruby red color with ruby hints. On the nose, ripe Spink black fruits, bramble, rose petal flowers, and tropical fruit aromas.\n",
      "Jainquest Côtes de Provence vines around 60 years old. Grilled seafood, sushains all the way to a\n",
      "\n",
      "PREDICTION 4\n",
      "\n",
      "\n",
      "Y. Tasty, bright fruit supporting to take a little brothers to milly attribute those, we are from the ground up. Today, the vineyards filled and cling cling in Lichine that invites their past few years he caltem of NOw to be took note (Beak and musts oldest Mondavi Winery in the 70s - Jz- minutes - a lingering mouthfeel tanks!\n",
      "\n",
      "Lajoro AlboN, founde\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5\n",
    "PREDICT_LEN = 350\n",
    "\n",
    "# Keras requires the batch size be specified ahead of time for stateful models.\n",
    "# We use a sequence length of 1, as we will be feeding in one character at a \n",
    "# time and predicting the next character.\n",
    "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
    "prediction_model.load_weights('data/models_weights/model_char_DESCS_chkpt_old.h5')\n",
    "\n",
    "# We seed the model with our initial string, copied BATCH_SIZE times\n",
    "\n",
    "seed_txt = 'This wine tastes like '\n",
    "seed_txt = ''.join(random.choices(string.ascii_uppercase + string.digits, k=20))\n",
    "seed = transform(seed_txt)\n",
    "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
    "\n",
    "# First, run the seed forward to prime the state of the model.\n",
    "prediction_model.reset_states()\n",
    "for i in range(len(seed_txt) - 1):\n",
    "    prediction_model.predict(seed[:, i:i + 1])\n",
    "\n",
    "# Now we can accumulate predictions!\n",
    "predictions = [seed[:, -1:]]\n",
    "for i in range(PREDICT_LEN):\n",
    "    last_word = predictions[-1]\n",
    "    next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
    "  \n",
    "  # sample from our output distribution\n",
    "    next_idx = [\n",
    "        np.random.choice(256, p=next_probits[i])\n",
    "        for i in range(BATCH_SIZE)\n",
    "    ]\n",
    "    predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
    "    \n",
    "for i in range(BATCH_SIZE):\n",
    "    print('PREDICTION %d\\n\\n' % i)\n",
    "    p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
    "    generated = ''.join([chr(c) for c in p])\n",
    "    print(generated)\n",
    "    print()\n",
    "    assert len(generated) == PREDICT_LEN, 'Generated text too short'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create BIG fake wine DESCRIPTION list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 36)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nA wine of breathtaking aromas of dark berries and wild strawberries in a New World sunshine  Tangerine, the stone savor, our nose, blackberry and fruit with notes of lime, and sweet honey, featurous balsam, slightly more slightly amber over a strict and moment throughout \\nDeep violet-black Signorello Cru Capine e not much keptn alcohol  Drinks   This Pinot flavor pairs well, with rich mint and the fruit and flows black fruits, pineapple, cinnamon, and cinnamon spice.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_conc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 1275/1275 [45:44<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "PREDICT_LEN = 600\n",
    "N_PREDICTIONS = 100\n",
    "\n",
    "# Keras requires the batch size be specified ahead of time for stateful models.\n",
    "# We use a sequence length of 1, as we will be feeding in one character at a \n",
    "# time and predicting the next character.\n",
    "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
    "prediction_model.load_weights('data/models_weights/model_char_DESCS_chkpt_old.h5')\n",
    "predicted_names = pd.read_csv('data/outputs/NAMES_v1.csv')\n",
    "\n",
    "N_PREDICTIONS = len(predicted_names)\n",
    "\n",
    "fake_NAME = []\n",
    "fake_DESC = []\n",
    "for ii in tqdm(range(N_PREDICTIONS)):\n",
    "    # We seed the model with our initial string, copied BATCH_SIZE times\n",
    "    #seed_array = np.zeros(shape=(BATCH_SIZE,))\n",
    "    for i in range(BATCH_SIZE):\n",
    "        seed_txt = predicted_names['name'][ii+i]\n",
    "        seed = transform(seed_txt)\n",
    "        #print(seed.shape)\n",
    "    seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
    "\n",
    "    # First, run the seed forward to prime the state of the model.\n",
    "    prediction_model.reset_states()\n",
    "    for i in range(len(seed_txt) - 1):\n",
    "        prediction_model.predict(seed[:, i:i + 1])\n",
    "\n",
    "    # Now we can accumulate predictions!\n",
    "    predictions = [seed[:, -1:]]\n",
    "    for i in range(PREDICT_LEN):\n",
    "        last_word = predictions[-1]\n",
    "        next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
    "\n",
    "      # sample from our output distribution\n",
    "        next_idx = [\n",
    "            np.random.choice(256, p=next_probits[i])\n",
    "            for i in range(BATCH_SIZE)\n",
    "        ]\n",
    "        predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        #print('PREDICTION %d\\n\\n' % i)\n",
    "        p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
    "        generated = ''.join([chr(c) for c in p])\n",
    "        #print(generated)\n",
    "        #print()\n",
    "        gen_list = generated.split('.')[1:-1]\n",
    "        gen_conc = ' '.join(gen_list) + '.'\n",
    "        fake_NAME.append(seed_txt)\n",
    "        fake_DESC.append(gen_conc)\n",
    "\n",
    "pd.DataFrame({'name'        : fake_NAME,\n",
    "              'description' : fake_DESC})\\\n",
    "    .to_csv('data/outputs/DESC_v1_2.csv', index=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(fake_NAME, 'data/outputs/fake_NAME')\n",
    "pd.to_pickle(fake_DESC, 'data/outputs/fake_DESC')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filepath = 'data/fake_desc_scores_v1.csv'\n",
    "pd.Series(fake_scores).to_csv(filepath)\n",
    "fake_DESC = pd.read_csv(filepath, names=['Name','Score'])\n",
    "fake_DESC = fake_DESC.loc[fake_DESC['Name'].str.len() > 20]\n",
    "len(fake_DESC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.title('Disitribution of fake wine descs to real ones')\n",
    "plt.hist(fake_DESC['Score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "real_names, descs_raw = pd.read_pickle(DATA_PATH)\n",
    "fake_scores = {}\n",
    "for f_name in tqdm(fake_names):\n",
    "    max_score = 0.0\n",
    "    for r_name in descs_raw:\n",
    "        if similar(f_name,r_name) > max_score:\n",
    "            max_score = similar(f_name,r_name)\n",
    "    fake_scores[f_name] = max_score\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "PREDICT_LEN = 250\n",
    "\n",
    "# Keras requires the batch size be specified ahead of time for stateful models.\n",
    "# We use a sequence length of 1, as we will be feeding in one character at a \n",
    "# time and predicting the next character.\n",
    "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
    "prediction_model.load_weights('/tmp/bard.h5')\n",
    "\n",
    "# We seed the model with our initial string, copied BATCH_SIZE times\n",
    "\n",
    "seed_txt = 'Looks it not like the king?  Verily, we must go! '\n",
    "seed = transform(seed_txt)\n",
    "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
    "\n",
    "# First, run the seed forward to prime the state of the model.\n",
    "prediction_model.reset_states()\n",
    "for i in range(len(seed_txt) - 1):\n",
    "    prediction_model.predict(seed[:, i:i + 1])\n",
    "\n",
    "# Now we can accumulate predictions!\n",
    "predictions = [seed[:, -1:]]\n",
    "for i in range(PREDICT_LEN):\n",
    "    last_word = predictions[-1]\n",
    "    next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
    "  \n",
    "  # sample from our output distribution\n",
    "    next_idx = [\n",
    "        np.random.choice(256, p=next_probits[i])\n",
    "        for i in range(BATCH_SIZE)\n",
    "    ]\n",
    "    predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
    "    \n",
    "for i in range(BATCH_SIZE):\n",
    "    print('PREDICTION %d\\n\\n' % i)\n",
    "    p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
    "    generated = ''.join([chr(c) for c in p])\n",
    "    print(generated)\n",
    "    print()\n",
    "    assert len(generated) == PREDICT_LEN, 'Generated text too short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
