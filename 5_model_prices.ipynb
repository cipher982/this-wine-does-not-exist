{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model, Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Flatten, Embedding\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "#import keras\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15191, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hall Napa Valley Cabernet Sauvignon 2013</td>\n",
       "      <td>54.99</td>\n",
       "      <td>Dark garnet in color, the 2013 HALL Napa Valle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rombauer Chardonnay 2017</td>\n",
       "      <td>36.99</td>\n",
       "      <td>Rombauer Vineyards was founded in 1982 by Koer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antinori Tignanello 2015</td>\n",
       "      <td>124.99</td>\n",
       "      <td>#24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Borne of Fire Cabernet Sauvignon 2016</td>\n",
       "      <td>19.99</td>\n",
       "      <td>Like a phoenix rising from the ashes, we have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Torbreck Woodcutters Shiraz 2017</td>\n",
       "      <td>21.99</td>\n",
       "      <td>This wine reflects the up and coming Shiraz vi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name   price  \\\n",
       "0  Hall Napa Valley Cabernet Sauvignon 2013   54.99   \n",
       "1                  Rombauer Chardonnay 2017   36.99   \n",
       "2                  Antinori Tignanello 2015  124.99   \n",
       "3     Borne of Fire Cabernet Sauvignon 2016   19.99   \n",
       "4          Torbreck Woodcutters Shiraz 2017   21.99   \n",
       "\n",
       "                                         description  \n",
       "0  Dark garnet in color, the 2013 HALL Napa Valle...  \n",
       "1  Rombauer Vineyards was founded in 1982 by Koer...  \n",
       "2                                               #24Â   \n",
       "3  Like a phoenix rising from the ashes, we have ...  \n",
       "4  This wine reflects the up and coming Shiraz vi...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "DATA_PATH = 'data/outputs/name_price_desc.csv'\n",
    "df_wines = pd.read_csv(DATA_PATH, sep='|', low_memory=False)\n",
    "\n",
    "# Clean pricing data\n",
    "df_wines['price'] =  df_wines['price'].str.strip('[]')\n",
    "df_wines = df_wines[df_wines['price'] != '']\n",
    "df_wines = df_wines[~df_wines['price'].str.contains(' ')]\n",
    "df_wines['price'] = df_wines['price'].astype(float)\n",
    "\n",
    "print(df_wines.shape)\n",
    "df_wines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21426\n",
      "Total length:  15191\n",
      "Length of first sequence:  49\n",
      "Max sequence length:  297\n",
      "Sample:  [48, 276, 6, 33, 1, 486, 98, 45, 42, 50]\n",
      "X:  (15191, 297)\n",
      "y:  (15191,)\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS = 2000\n",
    "\n",
    "# create/fit tokenizer, convert to sequences and pad for model input\n",
    "docs = df_wines['description'].astype(str)\n",
    "t = Tokenizer(num_words=NUM_WORDS)\n",
    "t.fit_on_texts(docs)\n",
    "encoded_seq = t.texts_to_sequences(docs)\n",
    "training_max_length = max([len(s) for s in encoded_seq])\n",
    "\n",
    "# define vocabulary size (largest integer value)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(vocab_size)\n",
    "\n",
    "X = pad_sequences(encoded_seq, maxlen=training_max_length, padding='post')\n",
    "y = df_wines['price']\n",
    "\n",
    "# Split out the training/testing datasets\n",
    "X_train,\\\n",
    "X_test,\\\n",
    "y_train,\\\n",
    "y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Print some statistics \n",
    "print(\"Sample count: \", len(encoded_seq))\n",
    "print(\"Length of first sequence: \", len(encoded_seq[0]))\n",
    "print(\"Max sequence length: \", training_max_length)\n",
    "print(\"Sample: \", encoded_seq[0][:10])\n",
    "print(\"X: \",X.shape)\n",
    "print(\"y: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 297, 2000)         42852000  \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 290, 16)           256016    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 145, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 2320)              0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 100)               232100    \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 43,340,217\n",
      "Trainable params: 43,340,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/500\n",
      " - 9s - loss: 34929.1128 - mean_squared_error: 34929.1128\n",
      "Epoch 2/500\n",
      " - 9s - loss: 31296.9888 - mean_squared_error: 31296.9888\n",
      "Epoch 3/500\n",
      " - 9s - loss: 27716.6100 - mean_squared_error: 27716.6100\n",
      "Epoch 4/500\n",
      " - 9s - loss: 24778.8764 - mean_squared_error: 24778.8764\n",
      "Epoch 5/500\n",
      " - 9s - loss: 23197.7427 - mean_squared_error: 23197.7427\n",
      "Epoch 6/500\n",
      " - 9s - loss: 21415.3717 - mean_squared_error: 21415.3717\n",
      "Epoch 7/500\n",
      " - 9s - loss: 20933.9855 - mean_squared_error: 20933.9855\n",
      "Epoch 8/500\n",
      " - 9s - loss: 19958.1553 - mean_squared_error: 19958.1553\n",
      "Epoch 9/500\n",
      " - 9s - loss: 19496.8006 - mean_squared_error: 19496.8006\n",
      "Epoch 10/500\n",
      " - 9s - loss: 19274.0390 - mean_squared_error: 19274.0390\n",
      "Epoch 11/500\n",
      " - 9s - loss: 19033.8026 - mean_squared_error: 19033.8026\n",
      "Epoch 12/500\n",
      " - 9s - loss: 18822.0734 - mean_squared_error: 18822.0734\n",
      "Epoch 13/500\n",
      " - 9s - loss: 18583.7861 - mean_squared_error: 18583.7861\n",
      "Epoch 14/500\n",
      " - 9s - loss: 18978.0899 - mean_squared_error: 18978.0899\n",
      "Epoch 15/500\n",
      " - 9s - loss: 18542.1337 - mean_squared_error: 18542.1337\n",
      "Epoch 16/500\n",
      " - 9s - loss: 18286.9813 - mean_squared_error: 18286.9813\n",
      "Epoch 17/500\n",
      " - 9s - loss: 18259.4895 - mean_squared_error: 18259.4895\n",
      "Epoch 18/500\n",
      " - 9s - loss: 17751.4244 - mean_squared_error: 17751.4244\n",
      "Epoch 19/500\n",
      " - 9s - loss: 17601.0877 - mean_squared_error: 17601.0877\n",
      "Epoch 20/500\n",
      " - 9s - loss: 17837.1849 - mean_squared_error: 17837.1849\n",
      "Epoch 21/500\n",
      " - 9s - loss: 18349.7050 - mean_squared_error: 18349.7050\n",
      "Epoch 22/500\n",
      " - 9s - loss: 17597.0699 - mean_squared_error: 17597.0699\n",
      "Epoch 23/500\n",
      " - 9s - loss: 17708.2766 - mean_squared_error: 17708.2766\n",
      "Epoch 24/500\n",
      " - 9s - loss: 17611.5594 - mean_squared_error: 17611.5594\n",
      "Epoch 25/500\n",
      " - 9s - loss: 18584.4269 - mean_squared_error: 18584.4269\n"
     ]
    }
   ],
   "source": [
    "LOSS_METRIC = 'mean_squared_error'\n",
    "\n",
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, NUM_WORDS, input_length=training_max_length))\n",
    "model.add(Conv1D(filters=16, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "print(model.summary())\n",
    "\n",
    "#d_model = Sequential()\n",
    "#d_model.add(Embedding(vocab_size, 250, input_length=max_length))\n",
    "#d_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "#d_model.add(Dense(64, kernel_initializer='normal',activation='relu'))\n",
    "#d_model.add(Dense(32, kernel_initializer='normal',activation='relu'))\n",
    "#d_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "checkpoint = ModelCheckpoint('data/models_weights/model_price.h5', \n",
    "                             monitor=LOSS_METRIC, \n",
    "                             verbose=0, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "early_stopping = EarlyStopping(monitor=LOSS_METRIC,\n",
    "                               patience=3,\n",
    "                               mode='min')\n",
    "tboard = keras.callbacks.TensorBoard(log_dir='./Graph',\n",
    "                                     histogram_freq=0, \n",
    "                                     write_graph=True, \n",
    "                                     write_images=True)\n",
    "callbacks_list = [checkpoint,early_stopping,tboard]\n",
    "\n",
    "# compile network\n",
    "model.compile(loss=LOSS_METRIC, \n",
    "              optimizer='adam',\n",
    "              metrics=['mse']\n",
    "              )\n",
    "# fit network\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          epochs=500, \n",
    "          callbacks=callbacks_list,\n",
    "          verbose=2)\n",
    "\n",
    "# Save weights\n",
    "model.save('data/models_weights/model_price.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when created the range they left howell mountain in a unique in napa valley on this eastern side of the valley one would expect to see the oak and found but the north air that across this makes howell mountain the and appellation in napa thus the and that the mountain help it blackberry minerality and dark chocolate the 2009 howell mountain cabernet sauvignon from the spectacular vineyard our source on howell mountain for\n",
      "[109.22215]\n",
      "\n",
      "\n",
      "brilliant ruby in color with a fresh fruity nose of red currants wild strawberries and a floral note the palate is packed with red fruit and hints of oak spice with velvety tannins\n",
      "[27.36819]\n",
      "\n",
      "\n",
      "the 2016 alta vineyard pinot a mix of and clones and was aged in french oak 50 new for 15 months before bottling this wine shows its high altitude location with a nose of bright berry fruit and ripe plums and a deeper color than what we typically see from the vineyard the texture of the alta is due to the time and ripening this vineyard the lush body and richness leads to a long balanced finish this wine should be at its best from through\n",
      "[24.424536]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample some predicted wines and prices\n",
    "predictions = model.predict(X_test)\n",
    "for i in range(1,4):\n",
    "    print(t.sequences_to_texts(X_test)[i])\n",
    "    print(predictions[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict prices on fake wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample count:  1275\n",
      "Length of first sequence:  62\n",
      "Sample:  [4, 341, 6, 165, 44, 1, 53, 35, 380, 35]\n"
     ]
    }
   ],
   "source": [
    "# Read in fake wine names and descriptions\n",
    "df_fake_wines = pd.read_csv('data/outputs/DESC_v1_2.csv',\n",
    "                            sep='|',\n",
    "                            low_memory=False)\n",
    "\n",
    "# Run the encodings as was done with training data\n",
    "encoded_seq = t.texts_to_sequences(df_fake_wines['description'])\n",
    "max_length = max([len(s) for s in encoded_seq])\n",
    "fake_X = pad_sequences(encoded_seq, maxlen=training_max_length, padding='post')\n",
    "\n",
    "print(\"Sample count: \", len(encoded_seq))\n",
    "print(\"Length of first sequence: \", len(encoded_seq[0]))\n",
    "print(\"Sample: \", encoded_seq[0][:10])\n",
    "\n",
    "assert X_train.shape[1] == fake_X.shape[1]\n",
    "fake_predictions = model.predict(fake_X)\n",
    "\n",
    "# Save to DF and CSV\n",
    "df_fake_wines['price'] = fake_predictions.astype(int)\n",
    "df_fake_wines.to_csv('data/outputs/fakes.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph Carr Reveliste Cinsault 2013</td>\n",
       "      <td>\\n\\nRaisage a trip back in time at the Frank F...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carol Shelton Roche TBredi 2016</td>\n",
       "      <td>\\nAromatics of this wine transporm nine expre...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finca Bolgheri Pinot Grigio 2018</td>\n",
       "      <td>This makes this opened scents, small whitehal...</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domaine de Cristict Chardonnay 2016</td>\n",
       "      <td>\\nDigest boasts an intensity, or gift W   This...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Domaine Dujac Fils &amp;amp; Pere Chambolle Rouge ...</td>\n",
       "      <td>On the nose, aromas of grapefruit, lime and a...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0               Joseph Carr Reveliste Cinsault 2013    \n",
       "1                   Carol Shelton Roche TBredi 2016    \n",
       "2                  Finca Bolgheri Pinot Grigio 2018    \n",
       "3               Domaine de Cristict Chardonnay 2016    \n",
       "4  Domaine Dujac Fils &amp; Pere Chambolle Rouge ...   \n",
       "\n",
       "                                         description  price  \n",
       "0  \\n\\nRaisage a trip back in time at the Frank F...     48  \n",
       "1   \\nAromatics of this wine transporm nine expre...     42  \n",
       "2   This makes this opened scents, small whitehal...     71  \n",
       "3  \\nDigest boasts an intensity, or gift W   This...    104  \n",
       "4   On the nose, aromas of grapefruit, lime and a...     22  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake_wines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
