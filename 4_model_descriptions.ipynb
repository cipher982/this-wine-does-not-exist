{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_PATH = 'data/pickles/descriptions.pickle'\n",
    "MODEL_WEIGHTS_PATH = 'data/models_weights/model_description_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Input text [4733481] Dark garnet in color, the 2013 HALL Napa Valley Ca\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[114, 114, 105, 101, 115,  32,  97, 110, 100,  32]]), array([[[114],\n",
       "         [105],\n",
       "         [101],\n",
       "         [115],\n",
       "         [ 32],\n",
       "         [ 97],\n",
       "         [110],\n",
       "         [100],\n",
       "         [ 32],\n",
       "         [ 99]]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text to arrays of letters represented as integers\n",
    "def transform(txt, pad_to=None):\n",
    "    # drop any non-ascii characters\n",
    "    output = np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n",
    "    if pad_to is not None:\n",
    "        output = output[:pad_to]\n",
    "        output = np.concatenate([\n",
    "            np.zeros([pad_to - len(txt)], dtype=np.int32),\n",
    "            output\n",
    "        ])\n",
    "    return output\n",
    "\n",
    "# How the characters will be fed into the model\n",
    "def training_generator(seq_len=100, batch_size=1024):\n",
    "    \"\"\"A generator yields (source, target) arrays for training.\"\"\"\n",
    "    names_raw, descs_raw = pd.read_pickle(DATA_PATH)\n",
    "    txt = '\\n'.join(descs_raw)\n",
    "    tf.logging.info('Input text [%d] %s', len(txt), txt[:50])\n",
    "    source = transform(txt)\n",
    "    while True:\n",
    "        offsets = np.random.randint(0, len(source) - seq_len, batch_size)\n",
    "        yield (\n",
    "            np.stack([source[idx:idx + seq_len] for idx in offsets]),\n",
    "            np.expand_dims(\n",
    "                np.stack([source[idx + 1:idx + seq_len + 1] for idx in offsets]), \n",
    "                -1),\n",
    "        )\n",
    "\n",
    "six.next(training_generator(seq_len=10, batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 512\n",
    "\n",
    "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
    "    \"\"\"Language model: predict the next word given the current word.\"\"\"\n",
    "    source = tf.keras.Input(\n",
    "        name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
    "\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
    "    lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
    "    lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
    "    #drop_1 = tf.keras.layers.Dropout(0.2)\n",
    "    predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n",
    "    model = tf.keras.Model(inputs=[source], outputs=[predicted_char])\n",
    "    #model = tf.keras.utils.multi_gpu_model(model, gpus=2)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.train.RMSPropOptimizer(learning_rate=0.01),\n",
    "        #optimizer=tf.keras.optimizers.RMSprop(lr=0.01),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "training_model = lstm_model(seq_len=100, batch_size=1024, stateful=False)\n",
    "#training_model.load_weights('model_small_chkpt.h5', by_name=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint('data/models_weights/model_char_DESCS_chkpt.h5', \n",
    "                             monitor='sparse_categorical_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')\n",
    "early_stopping = EarlyStopping(monitor='sparse_categorical_accuracy',\n",
    "                               patience=3,\n",
    "                               mode='max')\n",
    "callbacks_list = [checkpoint,early_stopping]\n",
    "\n",
    "training_model.fit_generator(\n",
    "    training_generator(seq_len=100, batch_size=1024),\n",
    "    steps_per_epoch=100,\n",
    "    epochs=50,\n",
    "    callbacks = callbacks_list\n",
    "    )\n",
    "\n",
    "training_model.save_weights(MODEL_WEIGHTS_PATH, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seed (InputLayer)            (1024, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (1024, 100, 512)          131072    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (1024, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1024, 100, 512)          2099200   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (1024, 100, 256)          131328    \n",
      "=================================================================\n",
      "Total params: 4,460,800\n",
      "Trainable params: 4,460,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show sample of created wine descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 0\n",
      "\n",
      "\n",
      "Y. The story is best known for its award-winnine experienced from all other vintage Champagne to unfold. As orphorng, Garnacha, Toro, Alivation that connoisseurs, as is the marriage of dried blynd sites, the wine is fruity, there is pleasant flavors of  plum fruits, jammavors, and a tea-leaf as thewine wild strawberry and raspberry flavors with a t\n",
      "\n",
      "PREDICTION 1\n",
      "\n",
      "\n",
      "Y. The vineyards are nestled about this Pinot noir and Cabernet Sauvignon and 2001. Laura blend offers complex nuances of apple flavors to a rivetting potential, intense depth and depth together toward almost hillside parcel above the earth and thanks to who introduce bears son, whole cluster (Armanding 200-acre estate located in Clavender, the REE\n",
      "\n",
      "PREDICTION 2\n",
      "\n",
      "\n",
      "Y.\n",
      "This bold Andalt was from his honored tradition and innovation in New Zealand winemaking. Villa naturally in the Napa Valley and intesticing bold growing conditions.\n",
      "\n",
      "Shrounded by the 92-acre Tigson to whom bust to Napa Valley, and provides the first new post-prohibits planted alcohol, and an easy-drinking, licorice, as watery, yet balanced by c\n",
      "\n",
      "PREDICTION 3\n",
      "\n",
      "\n",
      "Y. If you feed gave it touches of ripe pear, melon, and grapefruit, along with notes of pineapple, baked pear and delicious.\n",
      "A ruby red color with ruby hints. On the nose, ripe Spink black fruits, bramble, rose petal flowers, and tropical fruit aromas.\n",
      "Jainquest CÃ´tes de Provence vines around 60 years old. Grilled seafood, sushains all the way to a\n",
      "\n",
      "PREDICTION 4\n",
      "\n",
      "\n",
      "Y. Tasty, bright fruit supporting to take a little brothers to milly attribute those, we are from the ground up. Today, the vineyards filled and cling cling in Lichine that invites their past few years he caltem of NOw to be took note (Beak and musts oldest Mondavi Winery in the 70s - Jz- minutes - a lingering mouthfeel tanks!\n",
      "\n",
      "Lajoro AlboN, founde\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5\n",
    "PREDICT_LEN = 350\n",
    "\n",
    "# Keras requires the batch size be specified ahead of time for stateful models.\n",
    "# We use a sequence length of 1, as we will be feeding in one character at a \n",
    "# time and predicting the next character.\n",
    "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
    "prediction_model.load_weights(MODEL_WEIGHTS_PATH)\n",
    "\n",
    "# We seed the model with our initial string, copied BATCH_SIZE times\n",
    "seed_txt = 'This wine tastes like '\n",
    "seed_txt = ''.join(random.choices(string.ascii_uppercase + string.digits, k=20))\n",
    "seed = transform(seed_txt)\n",
    "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
    "\n",
    "# First, run the seed forward to prime the state of the model.\n",
    "prediction_model.reset_states()\n",
    "for i in range(len(seed_txt) - 1):\n",
    "    prediction_model.predict(seed[:, i:i + 1])\n",
    "\n",
    "# Now we can accumulate predictions!\n",
    "predictions = [seed[:, -1:]]\n",
    "for i in range(PREDICT_LEN):\n",
    "    last_word = predictions[-1]\n",
    "    next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
    "  \n",
    "  # sample from our output distribution\n",
    "    next_idx = [\n",
    "        np.random.choice(256, p=next_probits[i])\n",
    "        for i in range(BATCH_SIZE)\n",
    "    ]\n",
    "    predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
    "    \n",
    "for i in range(BATCH_SIZE):\n",
    "    print('PREDICTION %d\\n\\n' % i)\n",
    "    p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
    "    generated = ''.join([chr(c) for c in p])\n",
    "    print(generated)\n",
    "    print()\n",
    "    assert len(generated) == PREDICT_LEN, 'Generated text too short'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create larger fake wine description list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|âââââââââââââââââââââââââââââââââââââââââ| 1275/1275 [45:44<00:00,  2.10s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "PREDICT_LEN = 600\n",
    "N_PREDICTIONS = 100\n",
    "\n",
    "# Keras requires the batch size be specified ahead of time for stateful models.\n",
    "# We use a sequence length of 1, as we will be feeding in one character at a \n",
    "# time and predicting the next character.\n",
    "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
    "prediction_model.load_weights('data/models_weights/MODEL_WEIGHTS_PATH')\n",
    "predicted_names = pd.read_csv('data/outputs/NAMES_v1.csv')\n",
    "\n",
    "N_PREDICTIONS = len(predicted_names)\n",
    "\n",
    "fake_NAME = []\n",
    "fake_DESC = []\n",
    "for ii in tqdm(range(N_PREDICTIONS)):\n",
    "    # We seed the model with our initial string, copied BATCH_SIZE times\n",
    "    #seed_array = np.zeros(shape=(BATCH_SIZE,))\n",
    "    for i in range(BATCH_SIZE):\n",
    "        seed_txt = predicted_names['name'][ii+i]\n",
    "        seed = transform(seed_txt)\n",
    "        #print(seed.shape)\n",
    "    seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
    "\n",
    "    # First, run the seed forward to prime the state of the model.\n",
    "    prediction_model.reset_states()\n",
    "    for i in range(len(seed_txt) - 1):\n",
    "        prediction_model.predict(seed[:, i:i + 1])\n",
    "\n",
    "    # Now we can accumulate predictions!\n",
    "    predictions = [seed[:, -1:]]\n",
    "    for i in range(PREDICT_LEN):\n",
    "        last_word = predictions[-1]\n",
    "        next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
    "\n",
    "      # sample from our output distribution\n",
    "        next_idx = [\n",
    "            np.random.choice(256, p=next_probits[i])\n",
    "            for i in range(BATCH_SIZE)\n",
    "        ]\n",
    "        predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        #print('PREDICTION %d\\n\\n' % i)\n",
    "        p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
    "        generated = ''.join([chr(c) for c in p])\n",
    "        #print(generated)\n",
    "        #print()\n",
    "        gen_list = generated.split('.')[1:-1]\n",
    "        gen_conc = ' '.join(gen_list) + '.'\n",
    "        fake_NAME.append(seed_txt)\n",
    "        fake_DESC.append(gen_conc)\n",
    "\n",
    "pd.DataFrame({'name'        : fake_NAME,\n",
    "              'description' : fake_DESC})\\\n",
    "    .to_csv('data/outputs/DESC_v1_2.csv', index=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph Carr Reveliste Cinsault 2013</td>\n",
       "      <td>\\n\\nRaisage a trip back in time at the Frank F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carol Shelton Roche TBredi 2016</td>\n",
       "      <td>\\nAromatics of this wine transporm nine expre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finca Bolgheri Pinot Grigio 2018</td>\n",
       "      <td>This makes this opened scents, small whitehal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Domaine de Cristict Chardonnay 2016</td>\n",
       "      <td>\\nDigest boasts an intensity, or gift W   This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Domaine Dujac Fils &amp;amp; Pere Chambolle Rouge ...</td>\n",
       "      <td>On the nose, aromas of grapefruit, lime and a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0               Joseph Carr Reveliste Cinsault 2013    \n",
       "1                   Carol Shelton Roche TBredi 2016    \n",
       "2                  Finca Bolgheri Pinot Grigio 2018    \n",
       "3               Domaine de Cristict Chardonnay 2016    \n",
       "4  Domaine Dujac Fils &amp; Pere Chambolle Rouge ...   \n",
       "\n",
       "                                         description  \n",
       "0  \\n\\nRaisage a trip back in time at the Frank F...  \n",
       "1   \\nAromatics of this wine transporm nine expre...  \n",
       "2   This makes this opened scents, small whitehal...  \n",
       "3  \\nDigest boasts an intensity, or gift W   This...  \n",
       "4   On the nose, aromas of grapefruit, lime and a...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'name'        : fake_NAME,\n",
    "              'description' : fake_DESC}).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
