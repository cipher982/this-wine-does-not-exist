{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tensorflow import keras\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "#from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from keras.models import load_model\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SCRAPED_WINES_INPUT_PATH = 'data/scraped/names_prices_descriptions.pickle'\n",
    "MODEL_WEIGHTS_PATH = 'data/models_weights/model_weights_name.h5'\n",
    "\n",
    "print(tf.__version__)\n",
    "#!pip install tensorflow-gpu==1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "def transform(txt, pad_to=None):\n",
    "    # drop any non-ascii characters\n",
    "    output = np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n",
    "    if pad_to is not None:\n",
    "        output = output[:pad_to]\n",
    "        output = np.concatenate([\n",
    "            np.zeros([pad_to - len(txt)], dtype=np.int32),\n",
    "            output\n",
    "        ])\n",
    "    return output\n",
    "\n",
    "def training_generator(seq_len=100, batch_size=1024):\n",
    "    \"\"\"A generator yields (source, target) arrays for training.\"\"\"\n",
    "    wine_data = pd.read_pickle(SCRAPED_WINES_INPUT_PATH)\n",
    "    wine_data = wine_data['name'] # Take just the names for modeling\n",
    "    txt = '\\n'.join(wine_data)\n",
    "\n",
    "    #tf.logging.info('Input text [%d] %s', len(txt), txt[:50])\n",
    "    source = transform(txt)\n",
    "    while True:\n",
    "        offsets = np.random.randint(0, len(source) - seq_len, batch_size)\n",
    "\n",
    "        # Our model uses sparse crossentropy loss, but Keras requires labels\n",
    "        # to have the same rank as the input logits.  We add an empty final\n",
    "        # dimension to account for this.\n",
    "        yield (\n",
    "            np.stack([source[idx:idx + seq_len] for idx in offsets]),\n",
    "            np.expand_dims(\n",
    "                np.stack([source[idx + 1:idx + seq_len + 1] for idx in offsets]), \n",
    "                -1),\n",
    "        )\n",
    "\n",
    "#six.next(training_generator(seq_len=10, batch_size=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model and train it on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model2():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Embedding(input_dim=256, output_dim=32))\n",
    "    model.add(keras.layers.Dense(16, activation='relu'))\n",
    "    model.add(leras.layers.Dense(8, activation='relu'))\n",
    "    #model.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\david\\Documents\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "seed (InputLayer)            (1024, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (1024, 100, 128)          32768     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (1024, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1024, 100, 128)          131584    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (1024, 100, 256)          33024     \n",
      "=================================================================\n",
      "Total params: 328,960\n",
      "Trainable params: 328,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.5803 - sparse_categorical_accuracy: 0.1199\n",
      "Epoch 00001: sparse_categorical_accuracy improved from -inf to 0.11986, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 32s 315ms/step - loss: 3.5790 - sparse_categorical_accuracy: 0.1199\n",
      "Epoch 2/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.1294 - sparse_categorical_accuracy: 0.1726\n",
      "Epoch 00002: sparse_categorical_accuracy improved from 0.11986 to 0.17326, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 3.1254 - sparse_categorical_accuracy: 0.1733\n",
      "Epoch 3/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.5787 - sparse_categorical_accuracy: 0.2647\n",
      "Epoch 00003: sparse_categorical_accuracy improved from 0.17326 to 0.26490, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 2.5775 - sparse_categorical_accuracy: 0.2649\n",
      "Epoch 4/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.3986 - sparse_categorical_accuracy: 0.3021\n",
      "Epoch 00004: sparse_categorical_accuracy improved from 0.26490 to 0.30211, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 2.3981 - sparse_categorical_accuracy: 0.3021\n",
      "Epoch 5/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.2991 - sparse_categorical_accuracy: 0.3268\n",
      "Epoch 00005: sparse_categorical_accuracy improved from 0.30211 to 0.32687, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 2.2989 - sparse_categorical_accuracy: 0.3269\n",
      "Epoch 6/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.2200 - sparse_categorical_accuracy: 0.3483\n",
      "Epoch 00006: sparse_categorical_accuracy improved from 0.32687 to 0.34837, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 2.2197 - sparse_categorical_accuracy: 0.3484\n",
      "Epoch 7/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.1418 - sparse_categorical_accuracy: 0.3753\n",
      "Epoch 00007: sparse_categorical_accuracy improved from 0.34837 to 0.37545, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 2.1414 - sparse_categorical_accuracy: 0.3755\n",
      "Epoch 8/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 2.0608 - sparse_categorical_accuracy: 0.4029\n",
      "Epoch 00008: sparse_categorical_accuracy improved from 0.37545 to 0.40308, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 2.0604 - sparse_categorical_accuracy: 0.4031\n",
      "Epoch 9/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.9780 - sparse_categorical_accuracy: 0.4311\n",
      "Epoch 00009: sparse_categorical_accuracy improved from 0.40308 to 0.43121, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 1.9776 - sparse_categorical_accuracy: 0.4312\n",
      "Epoch 10/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.8997 - sparse_categorical_accuracy: 0.4590\n",
      "Epoch 00010: sparse_categorical_accuracy improved from 0.43121 to 0.45908, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 1.8993 - sparse_categorical_accuracy: 0.4591\n",
      "Epoch 11/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.8292 - sparse_categorical_accuracy: 0.4791\n",
      "Epoch 00011: sparse_categorical_accuracy improved from 0.45908 to 0.47921, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 1.8289 - sparse_categorical_accuracy: 0.4792\n",
      "Epoch 12/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.7653 - sparse_categorical_accuracy: 0.4959\n",
      "Epoch 00012: sparse_categorical_accuracy improved from 0.47921 to 0.49598, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 1.7649 - sparse_categorical_accuracy: 0.4960\n",
      "Epoch 13/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.7061 - sparse_categorical_accuracy: 0.5105\n",
      "Epoch 00013: sparse_categorical_accuracy improved from 0.49598 to 0.51058, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 1.7059 - sparse_categorical_accuracy: 0.5106\n",
      "Epoch 14/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.6557 - sparse_categorical_accuracy: 0.5227\n",
      "Epoch 00014: sparse_categorical_accuracy improved from 0.51058 to 0.52286, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 1.6552 - sparse_categorical_accuracy: 0.5229\n",
      "Epoch 15/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.6098 - sparse_categorical_accuracy: 0.5345\n",
      "Epoch 00015: sparse_categorical_accuracy improved from 0.52286 to 0.53459, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 1.6094 - sparse_categorical_accuracy: 0.5346\n",
      "Epoch 16/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.5716 - sparse_categorical_accuracy: 0.5450\n",
      "Epoch 00016: sparse_categorical_accuracy improved from 0.53459 to 0.54504, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 1.5714 - sparse_categorical_accuracy: 0.5450\n",
      "Epoch 17/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.5340 - sparse_categorical_accuracy: 0.5558\n",
      "Epoch 00017: sparse_categorical_accuracy improved from 0.54504 to 0.55585, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 1.5338 - sparse_categorical_accuracy: 0.5559\n",
      "Epoch 18/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.5026 - sparse_categorical_accuracy: 0.5643\n",
      "Epoch 00018: sparse_categorical_accuracy improved from 0.55585 to 0.56429, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 1.5025 - sparse_categorical_accuracy: 0.5643\n",
      "Epoch 19/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4739 - sparse_categorical_accuracy: 0.5721\n",
      "Epoch 00019: sparse_categorical_accuracy improved from 0.56429 to 0.57215, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 1.4738 - sparse_categorical_accuracy: 0.5722\n",
      "Epoch 20/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4466 - sparse_categorical_accuracy: 0.5795\n",
      "Epoch 00020: sparse_categorical_accuracy improved from 0.57215 to 0.57959, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.4464 - sparse_categorical_accuracy: 0.5796\n",
      "Epoch 21/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4238 - sparse_categorical_accuracy: 0.5860\n",
      "Epoch 00021: sparse_categorical_accuracy improved from 0.57959 to 0.58607, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.4237 - sparse_categorical_accuracy: 0.5861\n",
      "Epoch 22/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.4002 - sparse_categorical_accuracy: 0.5927\n",
      "Epoch 00022: sparse_categorical_accuracy improved from 0.58607 to 0.59269, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 1.4001 - sparse_categorical_accuracy: 0.5927\n",
      "Epoch 23/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.3807 - sparse_categorical_accuracy: 0.5985\n",
      "Epoch 00023: sparse_categorical_accuracy improved from 0.59269 to 0.59850, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.3806 - sparse_categorical_accuracy: 0.5985\n",
      "Epoch 24/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.3607 - sparse_categorical_accuracy: 0.6042\n",
      "Epoch 00024: sparse_categorical_accuracy improved from 0.59850 to 0.60421, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 1.3605 - sparse_categorical_accuracy: 0.6042\n",
      "Epoch 25/25\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.3430 - sparse_categorical_accuracy: 0.6093\n",
      "Epoch 00025: sparse_categorical_accuracy improved from 0.60421 to 0.60930, saving model to model_names_chkpt.h5\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.3429 - sparse_categorical_accuracy: 0.6093\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "EPOCHS = 25\n",
    "\n",
    "\n",
    "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
    "    \"\"\"Language model: predict the next word given the current word.\"\"\"\n",
    "    source = tf.keras.Input(\n",
    "        name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
    "\n",
    "    embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
    "    lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
    "    lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
    "    #drop_1 = tf.keras.layers.Dropout(0.2)\n",
    "    predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n",
    "    model = tf.keras.Model(inputs=[source], outputs=[predicted_char])\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        #optimizer=tf.keras.optimizers.RMSprop(lr=0.01),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['sparse_categorical_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "if 'session' in locals() and session is not None:\n",
    "    print('Close interactive session')\n",
    "    session.close()\n",
    "\n",
    "training_model = lstm_model(seq_len=100, batch_size=1024, stateful=False)\n",
    "#training_model.load_weights('model_small_chkpt.h5', by_name=True)\n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint('model_names_chkpt.h5', \n",
    "                             monitor='sparse_categorical_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max')\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='sparse_categorical_accuracy',\n",
    "                               patience=3,\n",
    "                               mode='max')\n",
    "callbacks_list = [checkpoint,early_stopping]\n",
    "\n",
    "print(training_model.summary())\n",
    "\n",
    "training_model.fit_generator(\n",
    "    training_generator(seq_len=100, batch_size=1024),\n",
    "    steps_per_epoch=100,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks = callbacks_list\n",
    "    )\n",
    "\n",
    "training_model.save_weights(MODEL_WEIGHTS_PATH, overwrite=True)\n",
    "\n",
    "# 16 = 3.5 loss (2 epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show sample of created wine names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION 0\n",
      "\n",
      "\n",
      "Qront'-Laond Rose\n",
      "Compmano Pinot Noir 2015\n",
      "Giane Dou Dos Allabellc Nouve d'Anta Cochauks-Jognon Lup-Pe 2015\n",
      "Pble Fovente Chandonnay 2014\n",
      "Matrman Cotes du Gobes Vineyard Pinot Noir 2017\n",
      "Hingdos Radara 2016\n",
      "Brijo Parvey Lesx Grenawer 2013\n",
      "Dons Fert 199\n",
      "\n",
      "PREDICTION 1\n",
      "\n",
      "\n",
      "Qast Bourges Gadon Pinot Noli Ly Rof Fipble Manchiani Vallay Farchy Blanch Bach Riascas Petit) (375ML half-bott Sadtre) 2016\n",
      "Tepezonna Reserra 2014\n",
      "Bentana de Maig Gigaco Rises Dank Mauaru 2016\n",
      "Roek Feut Carnione Rantonso Brut\n",
      "Ancers Cantersin Vailli\n",
      "\n",
      "PREDICTION 2\n",
      "\n",
      "\n",
      "Qhautit Brut\n",
      "Pecorom Sauvignon Blanc 2017\n",
      "Ferrare Quuvigngan River Monteccion Boundes Prigny Grenache 2017\n",
      "Gradoy Roaglie Clis Li Baralda Oralga Pinot Noir 2016\n",
      "Cyralo Pinot Povraity Pasinna Arnau 2015\n",
      "Errecto Old Cabernet Sauvignon 2016\n",
      "MacPi Brunel\n",
      "\n",
      "PREDICTION 3\n",
      "\n",
      "\n",
      "QApole Dimi Gavria 2011\n",
      "S'Agley T Post Brut Blanc 2017\n",
      "Qount Forgenn d'Ostono Pinot Noir 2016\n",
      "Bodeetine Pitar Merlot 2015\n",
      "Cato Valt Santario Jamasa Rax 2013\n",
      "Brostato Valles Chardonnay 2013\n",
      "Molba's Hadcolle 2016\n",
      "Seghhand Fadci Vintage le Cheblim) 2015\n",
      "\n",
      "PREDICTION 4\n",
      "\n",
      "\n",
      "QE Beuurs Coassa Coatar Souget Cotes du Hui Chabel) 2005\n",
      "Peche For Deqler Petit Mell La Rose 2017\n",
      "Peotsamo Grano Findra Rosco Pinot Noiir 2017\n",
      "Clos da Adura Altanos Chardonnay 2017\n",
      "Pillon Sancenint Vineyards Vitade Red 2014\n",
      "Mecsa Ribal Chardonnay 201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5\n",
    "PREDICT_LEN = 250\n",
    "\n",
    "# Keras requires the batch size be specified ahead of time for stateful models.\n",
    "# We use a sequence length of 1, as we will be feeding in one character at a \n",
    "# time and predicting the next character.\n",
    "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
    "prediction_model.load_weights(MODEL_WEIGHTS_PATH)\n",
    "\n",
    "seed_txt = ''.join(random.choices(string.ascii_uppercase + string.digits, k=20))\n",
    "seed = transform(seed_txt)\n",
    "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
    "\n",
    "# First, run the seed forward to prime the state of the model.\n",
    "prediction_model.reset_states()\n",
    "for i in range(len(seed_txt) - 1):\n",
    "    prediction_model.predict(seed[:, i:i + 1])\n",
    "\n",
    "# Now we can accumulate predictions!\n",
    "predictions = [seed[:, -1:]]\n",
    "for i in range(PREDICT_LEN):\n",
    "    last_word = predictions[-1]\n",
    "    next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
    "  \n",
    "  # sample from our output distribution\n",
    "    next_idx = [\n",
    "        np.random.choice(256, p=next_probits[i])\n",
    "        for i in range(BATCH_SIZE)\n",
    "    ]\n",
    "    predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
    "    \n",
    "for i in range(BATCH_SIZE):\n",
    "    print('PREDICTION %d\\n\\n' % i)\n",
    "    p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
    "    generated = ''.join([chr(c) for c in p])\n",
    "    print(generated)\n",
    "    print()\n",
    "    assert len(generated) == PREDICT_LEN, 'Generated text too short'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create larger fake wine name list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [08:20<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 5\n",
    "PREDICT_LEN = 150\n",
    "TOTAL_BATCHES = 1000\n",
    "\n",
    "# We use a sequence length of 1, as we will be feeding in one character at a \n",
    "# time and predicting the next character.\n",
    "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
    "prediction_model.load_weights(MODEL_WEIGHTS_PATH)\n",
    "\n",
    "fake_names = []\n",
    "for ii in tqdm(range(TOTAL_BATCHES)):\n",
    "    seed_txt = ''.join(random.choices(string.ascii_uppercase + string.digits, k=20))\n",
    "    seed = transform(seed_txt)\n",
    "    seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
    "\n",
    "    # First, run the seed forward to prime the state of the model.\n",
    "    prediction_model.reset_states()\n",
    "    for i in range(len(seed_txt) - 1):\n",
    "        prediction_model.predict(seed[:, i:i + 1])\n",
    "\n",
    "    # Now we can accumulate predictions!\n",
    "    predictions = [seed[:, -1:]]\n",
    "    for i in range(PREDICT_LEN):\n",
    "        last_word = predictions[-1]\n",
    "        next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
    "\n",
    "      # sample from our output distribution\n",
    "        next_idx = [\n",
    "            np.random.choice(256, p=next_probits[i])\n",
    "            for i in range(BATCH_SIZE)\n",
    "        ]\n",
    "        predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        #print('PREDICTION %d\\n\\n' % i)\n",
    "        p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
    "        generated = ''.join([chr(c) for c in p])\n",
    "        gen_list = generated.split('\\n')[1:-1]\n",
    "        for item in gen_list:\n",
    "            fake_names.append(item)\n",
    "        assert len(generated) == PREDICT_LEN, 'Generated text too short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fake_names_14039_2019-11-15.pickle\n"
     ]
    }
   ],
   "source": [
    "fileName = \"fake_names_{}_{}.pickle\".format(len(fake_names),str(dt.date.today()))\n",
    "pd.to_pickle(fake_names, 'data/fake/' + fileName)\n",
    "print(\"Saved {}\".format(fileName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute fake wine name similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/fake/fakes.csv', low_memory=False, sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                          | 43/14039 [00:56<4:38:30,  1.19s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b542a55915f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmax_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mr_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreal_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mmax_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-b542a55915f8>\u001b[0m in \u001b[0;36msimilar\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msimilar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mSequenceMatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#fake_names = test['name']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python36\\Lib\\difflib.py\u001b[0m in \u001b[0;36mratio\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \"\"\"\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtriple\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_matching_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_calculate_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python36\\Lib\\difflib.py\u001b[0m in \u001b[0;36mget_matching_blocks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[0malo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbhi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m             \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_longest_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbhi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m             \u001b[1;31m# a[alo:i] vs b[blo:j] unknown\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[1;31m# a[i:i+k] same as b[j:j+k]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\david\\appdata\\local\\programs\\python\\python36\\Lib\\difflib.py\u001b[0m in \u001b[0;36mfind_longest_match\u001b[1;34m(self, alo, ahi, blo, bhi)\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbestsize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m                     \u001b[0mbesti\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbestsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m             \u001b[0mj2len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewj2len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;31m# Extend the best by non-junk elements on each end.  In particular,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########## This code is super slow if matching large lists ##########\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "#fake_names = test['name']\n",
    "real_names = pd.read_pickle(SCRAPED_WINES_INPUT_PATH)['name']\n",
    "\n",
    "fake_scores = {}\n",
    "for f_name in tqdm(fake_names):\n",
    "    max_score = 0.0\n",
    "    for r_name in real_names:\n",
    "        score = similar(f_name, r_name)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "    fake_scores[f_name] = max_score\n",
    "        \n",
    "    \n",
    "fake_scores = pd.Series(fake_scores)\n",
    "\n",
    "########## This code is super slow if matching large lists ##########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ^^ Above code takes ~8 hours to run, the files in the extra_code directory will split it out among 8 processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for wine names that match real ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fake names:  1601\n",
      "Total 90% or less match:  1137\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAGxCAYAAACju/aQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X1cFXX+///nkYsDIpxE5EpRycyL8NpS1BKvMBVtS7dMI+3CLtRaU3c/WlvqVlpZpmtl5bpaaku1XmRqJGpaLlhqUamtq6UrbiDmBSgpKL5/f/Rjvh7Bi4MgAz7ut9vcbp73vGfmNe8zh/N0zsw5DmOMEQAAgE1Vq+gCAAAALoSwAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wUsnMnz9fDofDmvz8/BQeHq6uXbtq6tSpys7OLrbMpEmT5HA4PN6Ww+HQpEmTrMc7duzQpEmTtHfvXo/WExcXp7i4OOvx3r175XA49PLLL3tc04VMmTJFy5YtK9a+fv16ORwOrV+/vky3V9ZmzZql6667Tr6+vnI4HDp69Oh5+77//vu64YYb5O/vL4fDofT09EveTtExtGXLlrIou0wV1ebpMYbSSU1N1aRJky54rFUG5/6tQtVDWKmk5s2bp7S0NKWkpOj1119Xq1at9OKLL6pp06Zas2aNW98HH3xQaWlpHm8jLS1NDz74oPV4x44dmjx5ssdvJG+88YbeeOMNj7fvqfOFlTZt2igtLU1t2rQp9xpKKz09XY8//ri6du2qdevWKS0tTYGBgSX2PXjwoBITE9WwYUMlJycrLS1N119//RWuuHz07dtXaWlpioiIqOhSrgqpqamaPHlypQ8rqPq8K7oAlE5MTIzatWtnPR4wYICeeOIJde7cWXfccYd27dqlsLAwSVLdunVVt25dj7fRoUOHy6rx119/VfXq1dWsWbPLWs/lCgoKuux9KW/bt2+XJA0fPlw33XTTBfv+5z//0alTp3TPPfeoS5cuV6K8K6Z27dqqXbt2RZeBclD09wAoDc6sVCH16tXTK6+8omPHjumtt96y2kv6GGjdunWKi4tTrVq15O/vr3r16mnAgAH69ddfrT5nn1qdP3++fv/730uSunbtan0MNX/+fEm/fdQTExOjzz//XB07dlT16tV1//33W/PO/hioyJkzZ/T888+rXr168vPzU7t27bR27Vq3PsOGDVODBg2KLXvuPjkcDuXl5emdd96xaiva5vk+Blq+fLliY2NVvXp1BQYGqmfPnsXOQBVtZ/v27br77rvlcrkUFham+++/Xzk5OcXqKsnf//53tWzZUn5+fgoODtbtt9+uH374wZofFxene+65R5LUvn17ORwODRs2rMR1DRs2TJ07d5Yk3XXXXW77uWXLFg0aNEgNGjSQv7+/GjRooLvvvlv//e9/L1pjZmam2rZtq0aNGmnXrl1W+5YtW9S/f38FBwfLz89PrVu31gcffHDR9d14443q27evW1vz5s3lcDi0efNmq23JkiVyOBz6/vvvJZX8MVDRsbV582bdfPPNql69uq699lq98MILOnPmjNs2cnNzNW7cOEVHR8vX11d16tTR6NGjlZeXd9GaL3U7J0+e1NixY9WqVSu5XC4FBwcrNjZWH330UbF1OhwOjRo1SvPmzVPjxo3l7++vdu3aadOmTTLGaNq0aYqOjlaNGjXUrVs37d69u9g61qxZo+7duysoKEjVq1dXp06dir1ODh48qIceekhRUVFyOp2qXbu2OnXqVOws69kmTZqkP/7xj5Kk6Oho63VT9Do5c+aMXnrpJTVp0kROp1OhoaG69957tX///ouOZdHr5uuvv9bAgQNVs2ZNNWzY0Jp/KcfVwYMHNWLECDVr1kw1atRQaGiounXrpi+++OKi2z+fw4cPa8SIEapTp458fX117bXX6qmnnlJ+fr5bv6LnbcGCBWratKmqV6+uli1basWKFcXWuWvXLg0ePFihoaFyOp1q2rSpXn/9dbc+Z86c0XPPPWcdA9dcc41atGihmTNnlnpfrjoGlcq8efOMJLN58+YS5x8/ftx4eXmZ7t27W20TJ040Zz/Ve/bsMX5+fqZnz55m2bJlZv369WbRokUmMTHRHDlyxOonyUycONEYY0x2draZMmWKkWRef/11k5aWZtLS0kx2drYxxpguXbqY4OBgExUVZWbNmmU+++wzs2HDBmtely5d3LYvyURFRZnOnTubxYsXmw8//NDceOONxsfHx6Smplp9hw4daurXr19sP8/dp7S0NOPv72/69Olj1bZ9+3ZjjDGfffaZkWQ+++wzq/+iRYuMJBMfH2+WLVtm3n//fdO2bVvj6+trvvjii2Lbady4sXnmmWdMSkqKmT59unE6nea+++4739NkKRqzu+++26xcudK8++675tprrzUul8v85z//McYYs337dvPnP//ZSDLz5s0zaWlpZvfu3SWub/fu3eb11183ksyUKVPc9vPDDz80zzzzjFm6dKnZsGGDSUpKMl26dDG1a9c2Bw8etNZx7jH0/fffm6ioKBMbG+vWb926dcbX19fcfPPN5v333zfJyclm2LBhVp0XMn78eFOjRg1TUFBgjDEmKyvLSDL+/v7m+eeft/o9+uijJiwsrFhte/bssdq6dOliatWqZRo1amTefPNNk5KSYkaMGGEkmXfeecfql5eXZ1q1amVCQkLM9OnTzZo1a8zMmTONy+Uy3bp1M2fOnLlgzZe6naNHj5phw4aZBQsWmHXr1pnk5GQzbtw4U61aNbd+xvz2Gqpfv77p2LGjWbJkiVm6dKm5/vrrTXBwsHniiSfMbbfdZlasWGEWLVpkwsLCTIsWLdzqXLBggXE4HOZ3v/udWbJkifn4449NQkKC8fLyMmvWrLH69erVy9SuXdu8/fbbZv369WbZsmXmmWeeMUlJSefd34yMDPPYY48ZSWbJkiXW6yYnJ8cYY8xDDz1kJJlRo0aZ5ORk8+abb5ratWubqKgot+OkJEWvm/r165v/+7//MykpKWbZsmXGmEs/rv7973+bRx991CQlJZn169ebFStWmAceeMBUq1bN7bVcNM5Ff6vO58SJE6ZFixYmICDAvPzyy2b16tXm6aefNt7e3qZPnz7F1tegQQNz0003mQ8++MCsWrXKxMXFGW9vb/Pjjz9a/bZv325cLpdp3ry5effdd83q1avN2LFjTbVq1cykSZOsflOnTjVeXl5m4sSJZu3atSY5OdnMmDHDrQ8ujLBSyVwsrBhjTFhYmGnatKn1+Nw39n/+859GkklPT7/gts79A/Dhhx8We9Mv0qVLFyPJrF27tsR5JYWVyMhIc+LECas9NzfXBAcHmx49elhtlxpWjDEmICDADB06tFjfc8NKYWGhiYyMNM2bNzeFhYVWv2PHjpnQ0FDTsWPHYtt56aWX3NY5YsQI4+fnd8E3wCNHjlgB6mz79u0zTqfTDB482Gq7lOf13P358MMPL9jv9OnT5vjx4yYgIMDMnDmzxG2lpKSYoKAgM3DgQLfnwhhjmjRpYlq3bm1OnTrl1p6QkGAiIiLcxu5ca9asMZLM559/bowxZuHChSYwMNCMGDHCdO3a1erXqFGjEsfh3LAiyXz55Zdu22jWrJnp1auX9Xjq1KmmWrVqxcaw6HhftWrVeev1ZDvnOn36tDl16pR54IEHTOvWrd3mSTLh4eHm+PHjVtuyZcuMJNOqVSu342fGjBlGkvnuu++MMb+Fr+DgYNOvXz+3dRYWFpqWLVuam266yWqrUaOGGT169AX3ryTTpk0rNt7GGPPDDz8YSWbEiBFu7V9++aWRZJ588skLrrfodfPMM88Um1fa46ponLt3725uv/12t3mXElbefPNNI8l88MEHbu0vvviikWRWr17ttr6wsDCTm5trtWVlZZlq1aqZqVOnWm29evUydevWtQJekVGjRhk/Pz9z+PBha99atWp1wfpwYXwMVAUZYy44v1WrVvL19dVDDz2kd955Rz/99FOZbLdmzZrq1q3bJfe/44475OfnZz0ODAxUv3799Pnnn6uwsLBMairJzp079fPPPysxMVHVqv2/l0CNGjU0YMAAbdq0ye3jMEnq37+/2+MWLVro5MmTJd59VSQtLU0nTpwo9pFOVFSUunXrVuxU/uU6fvy4/u///k/XXXedvL295e3trRo1aigvL8/tY6ci77zzjvr06aMHH3xQH3zwgdtzsXv3bv373//WkCFDJEmnT5+2pj59+igzM1M7d+48by2dOnWSn5+f9TFESkqK4uLidOuttyo1NVW//vqrMjIytGvXLvXo0eOi+xYeHl7sWp4WLVq4fcS1YsUKxcTEqFWrVm719urV65LvBruU7UjShx9+qE6dOqlGjRry9vaWj4+P5s6dW+I4d+3aVQEBAdbjpk2bSpJ69+7t9lFmUXvRtlJTU3X48GENHTrUbX/OnDmjW2+9VZs3b7Y+3rrppps0f/58Pffcc9q0aZNOnTp10X29kM8++0ySih27N910k5o2bXrJx+6AAQPcHnt6XL355ptq06aN/Pz8rHFeu3ZtieN8MevWrVNAQIAGDhzo1l60j+fuU9euXd0ucg8LC1NoaKj1/Jw8eVJr167V7bffrurVqxfbl5MnT2rTpk2Sfhu3b7/9ViNGjNCnn36q3Nxcj+u/2hFWqpi8vDwdOnRIkZGR5+3TsGFDrVmzRqGhoRo5cqQaNmyohg0bXvbnp57ewREeHl5iW0FBgY4fP35ZtVzIoUOHJJVcb2RkpM6cOaMjR464tdeqVcvtsdPplCSdOHGi1Nspml9WBg8erNdee00PPvigPv30U3311VfavHmzateuXWKdSUlJ8vf314MPPljsmqYDBw5IksaNGycfHx+3acSIEZKkX3755by1+Pn5uV0zsXbtWvXs2VNxcXEqLCzUF198oZSUFEm6pLBy7vhLvz0HZ+/XgQMH9N133xWrNzAwUMaYC9bryXaWLFmiO++8U3Xq1NHChQuVlpamzZs36/7779fJkyeLLR8cHOz22NfX94LtResoeg4GDhxYbJ9efPFFGWN0+PBhSb/dyj506FD97W9/U2xsrIKDg3XvvfcqKyvrovtckrI6ds9d3pPjavr06Xr00UfVvn17LV68WJs2bdLmzZt16623XvB1d6F9Cg8PL3ash4aGytvbu9g+XexYOHTokE6fPq1Zs2YV25c+ffq47cuECRP08ssva9OmTerdu7dq1aql7t272/LrA+yKu4GqmJUrV6qwsLDEC1rPdvPNN+vmm29WYWGhtmzZolmzZmn06NEKCwvToEGDSrVtT7/LpaQ/pFlZWfL19VWNGjUk/famd+7Fb9KF3ygvpuiPUGZmZrF5P//8s6pVq6aaNWuWev2Xup2QkJDL3kaRnJwcrVixQhMnTtT48eOt9vz8fOsN7VyLFi3Sn//8Z3Xp0kWrV69Wq1atrHlFtU2YMEF33HFHics3btz4gjV1795dzzzzjL766ivt379fPXv2VGBgoG688UalpKTo559/1vXXX6+oqChPd7dEISEh8vf319///vfzzi8LCxcuVHR0tN5//323Y76k4/RyFNU7a9as897NVnTHX0hIiGbMmKEZM2Zo3759Wr58ucaPH6/s7GwlJyd7vO2zj91z7yT05Ng992+CJ8fVwoULFRcXp9mzZ7vNP3bs2CVt+1y1atXSl19+KWOMW13Z2dk6ffq0x8dHzZo15eXlpcTERI0cObLEPtHR0ZIkb29vjRkzRmPGjNHRo0e1Zs0aPfnkk+rVq5cyMjK4S+oSEFaqkH379mncuHFyuVx6+OGHL2kZLy8vtW/fXk2aNNGiRYv09ddfnzesXMrZBE8sWbJE06ZNsz5+OHbsmD7++GPdfPPN8vLykiQ1aNBA2dnZOnDggPWHuaCgQJ9++mmJ9V1KbY0bN1adOnX03nvvady4cdYfrry8PC1evNi6Q+hyxcbGyt/fXwsXLrTupJKk/fv3a926dcVOR18Oh8MhY4z1HBX529/+dt6P1IKDg7V27VolJCSoa9eu+uSTT6w3xcaNG6tRo0b69ttvNWXKlFLV1KNHDz355JN6+umnVbduXTVp0sRqX758ubKysop9THA5EhISNGXKFNWqVct6kygPDofD+uK+IllZWSXeDXQ5OnXqpGuuuUY7duzQqFGjLnm5evXqadSoUVq7dq3+9a9/XbDv+V7TRR/nLly4UDfeeKPVvnnzZv3www966qmnLrmes3lyXDkcjmLH83fffae0tLRSBdzu3bvrgw8+0LJly3T77bdb7e+++6413xPVq1dX165d9c0336hFixbWmbGLueaaazRw4ED973//0+jRo7V3794K/3qHyoCwUklt27bN+nw0OztbX3zxhebNmycvLy8tXbr0gt9V8eabb2rdunXq27ev6tWrp5MnT1r/G73QKfmYmBhJ0ttvv63AwED5+fkpOjq6xNOll8LLy0s9e/bUmDFjdObMGb344ovKzc3V5MmTrT533XWXnnnmGQ0aNEh//OMfdfLkSf31r38t8Q24efPmWr9+vT7++GNFREQoMDCwxP/9V6tWTS+99JKGDBmihIQEPfzww8rPz9e0adN09OhRvfDCC6Xan3Ndc801evrpp/Xkk0/q3nvv1d13361Dhw5p8uTJ8vPz08SJE8tkO9Jv3yVzyy23aNq0aQoJCVGDBg20YcMGzZ07V9dcc815lwsMDFRycrLuuOMO9ezZU8uXL1fXrl0lSW+99ZZ69+6tXr16adiwYapTp44OHz6sH374QV9//bU+/PDDC9bUtm1b1axZU6tXr9Z9991ntffo0UPPPvus9e+yMnr0aC1evFi33HKLnnjiCbVo0UJnzpzRvn37tHr1ao0dO1bt27e/7O0kJCRoyZIlGjFihAYOHKiMjAw9++yzioiIcLvt+3LVqFFDs2bN0tChQ3X48GENHDhQoaGhOnjwoL799lsdPHhQs2fPVk5Ojrp27arBgwerSZMmCgwM1ObNm63n9UKaN28uSZo5c6aGDh0qHx8fNW7cWI0bN9ZDDz2kWbNmqVq1aurdu7f27t2rp59+WlFRUXriiSdKvV+XelwlJCTo2Wef1cSJE9WlSxft3LlTf/nLXxQdHa3Tp097vN17771Xr7/+uoYOHaq9e/eqefPm2rhxo6ZMmaI+ffqU6licOXOmOnfurJtvvlmPPvqoGjRooGPHjmn37t36+OOPtW7dOklSv379rO/Gql27tv773/9qxowZql+/vho1auTxdq9KFXp5LzxWdLdE0eTr62tCQ0NNly5dzJQpU6xbic9W0m2+t99+u6lfv75xOp2mVq1apkuXLmb58uVuy6mEK+xnzJhhoqOjjZeXl9uthl26dDE33HBDiTWf726gF1980UyePNnUrVvX+Pr6mtatW5tPP/202PKrVq0yrVq1Mv7+/ubaa681r732Wol3A6Wnp5tOnTqZ6tWrG0nWNku6ddmY3+7KaN++vfHz8zMBAQGme/fu5l//+leJY3furZol3bVyPn/7299MixYtjK+vr3G5XOa2226zbjc+d32XczfQ/v37zYABA0zNmjVNYGCgufXWW822bdtM/fr13e6SKmlb+fn5ZsCAAcbPz8+sXLnSav/222/NnXfeaUJDQ42Pj48JDw833bp1M2+++eZF6zTGmNtvv91IMosWLbLaCgoKTEBAgKlWrZrbrfJn13bu3UAlHVsl3Sl2/Phx8+c//9k0btzYGu/mzZubJ554wmRlZV2wVk+288ILL5gGDRoYp9NpmjZtaubMmVPiMSnJjBw50q2t6PifNm2aW/v5ntcNGzaYvn37muDgYOPj42Pq1Klj+vbta/U7efKkeeSRR0yLFi1MUFCQ8ff3N40bNzYTJ040eXl5F9xnY4yZMGGCiYyMNNWqVSt219yLL75orr/+euPj42NCQkLMPffcYzIyMi66zvO9bopcynGVn59vxo0bZ+rUqWP8/PxMmzZtzLJly0p8Pkr6W1WSQ4cOmUceecREREQYb29vU79+fTNhwgRz8uTJYus793kzxhR7LRnz2/N5//33mzp16hgfHx9Tu3Zt07FjR/Pcc89ZfV555RXTsWNHExISYnx9fU29evXMAw88YPbu3XvRmvEbhzEXuXUEAACgAnE3EAAAsDXCCgAAsDXCCgAAsDXCCgAAsDXCCgAAsDXCCgAAsLVK+aVwZ86c0c8//6zAwECPv+IdAABUDGOMjh07psjISLcfkr2YShlWfv755zL7PREAAHBlZWRkFPvdqQuplGGl6Ge7MzIyFBQUVMHVAACAS5Gbm6uoqCjrffxSVcqwUvTRT1BQEGEFAIBKxtNLOC7rAtupU6fK4XBo9OjRVlt+fr4ee+wxhYSEKCAgQP3799f+/fvdltu3b5/69eungIAAhYSE6PHHH1dBQcHllAIAAKqoUoeVzZs36+2331aLFi3c2kePHq2lS5cqKSlJGzdu1PHjx5WQkGD9Sm5hYaH69u2rvLw8bdy4UUlJSVq8eLHGjh17eXsCAACqpFKFlePHj2vIkCGaM2eOatasabXn5ORo7ty5euWVV9SjRw+1bt1aCxcu1Pfff681a9ZIklavXq0dO3Zo4cKFat26tXr06KFXXnlFc+bMUW5ubtnsFQAAqDJKFVZGjhypvn37qkePHm7tW7du1alTpxQfH2+1RUZGKiYmRqmpqZKktLQ0xcTEKDIy0urTq1cv5efna+vWrSVuLz8/X7m5uW4TAAC4Onh8gW1SUpK2bt2qLVu2FJuXlZUlX19ft7MtkhQWFqasrCyrT1hYmNv8mjVrytfX1+pzrqlTp2ry5MmelgoAAKoAj86sZGRk6A9/+IMWLVokPz+/S17OGON25W9JVwGf2+dsEyZMUE5OjjVlZGR4UjYAAKjEPAorW7duVXZ2ttq2bStvb295e3trw4YN+utf/ypvb2+FhYWpoKBAR44ccVsuOzvbOpsSHh5e7AzKkSNHdOrUqWJnXIo4nU7rNmVuVwYA4OriUVjp3r27vv/+e6Wnp1tTu3btNGTIEOvfPj4+SklJsZbJzMzUtm3b1LFjR0lSbGystm3bpszMTKvP6tWr5XQ61bZt2zLaLQAAUFV4dM1KYGCgYmJi3NoCAgJUq1Ytq/2BBx7Q2LFjVatWLQUHB2vcuHFq3ry5dTFufHy8mjVrpsTERE2bNk2HDx/WuHHjNHz4cM6YAACAYsr8G2xfffVVeXt7684779SJEyfUvXt3zZ8/X15eXpIkLy8vrVy5UiNGjFCnTp3k7++vwYMH6+WXXy7rUgAAQBXgMMaYii7CU7m5uXK5XMrJyeFsDAAAlURp378v6+v2AQAAyhthBQAA2BphBQAA2FqZX2ALAADcNRi/sqJL8NjeF/pWdAkWzqwAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABbI6wAAABb8yiszJ49Wy1atFBQUJCCgoIUGxurTz75xJofFxcnh8PhNg0aNMhtHUeOHFFiYqJcLpdcLpcSExN19OjRstkbAABQ5XgUVurWrasXXnhBW7Zs0ZYtW9StWzfddttt2r59u9Vn+PDhyszMtKa33nrLbR2DBw9Wenq6kpOTlZycrPT0dCUmJpbN3gAAgCrH25PO/fr1c3v8/PPPa/bs2dq0aZNuuOEGSVL16tUVHh5e4vI//PCDkpOTtWnTJrVv316SNGfOHMXGxmrnzp1q3LhxafYBAABUYaW+ZqWwsFBJSUnKy8tTbGys1b5o0SKFhITohhtu0Lhx43Ts2DFrXlpamlwulxVUJKlDhw5yuVxKTU0977by8/OVm5vrNgEAgKuDR2dWJOn7779XbGysTp48qRo1amjp0qVq1qyZJGnIkCGKjo5WeHi4tm3bpgkTJujbb79VSkqKJCkrK0uhoaHF1hkaGqqsrKzzbnPq1KmaPHmyp6UCAIAqwOOw0rhxY6Wnp+vo0aNavHixhg4dqg0bNqhZs2YaPny41S8mJkaNGjVSu3bt9PXXX6tNmzaSJIfDUWydxpgS24tMmDBBY8aMsR7n5uYqKirK09IBAEAl5HFY8fX11XXXXSdJateunTZv3qyZM2cWu5BWktq0aSMfHx/t2rVLbdq0UXh4uA4cOFCs38GDBxUWFnbebTqdTjmdTk9LBQAAVcBlf8+KMUb5+fklztu+fbtOnTqliIgISVJsbKxycnL01VdfWX2+/PJL5eTkqGPHjpdbCgAAqII8OrPy5JNPqnfv3oqKitKxY8eUlJSk9evXKzk5WT/++KMWLVqkPn36KCQkRDt27NDYsWPVunVrderUSZLUtGlT3XrrrRo+fLh1Juahhx5SQkICdwIBAIASeRRWDhw4oMTERGVmZsrlcqlFixZKTk5Wz549lZGRobVr12rmzJk6fvy4oqKi1LdvX02cOFFeXl7WOhYtWqTHH39c8fHxkqT+/fvrtddeK9u9AgAAVYbDGGMqughP5ebmyuVyKScnR0FBQRVdDgAAF9Rg/MqKLsFje1/oW+brLO37N78NBAAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbI2wAgAAbM2jsDJ79my1aNFCQUFBCgoKUmxsrD755BNrfn5+vh577DGFhIQoICBA/fv31/79+900XA6JAAAfzklEQVTWsW/fPvXr108BAQEKCQnR448/roKCgrLZGwAAUOV4FFbq1q2rF154QVu2bNGWLVvUrVs33Xbbbdq+fbskafTo0Vq6dKmSkpK0ceNGHT9+XAkJCSosLJQkFRYWqm/fvsrLy9PGjRuVlJSkxYsXa+zYsWW/ZwAAoEpwGGPM5awgODhY06ZN08CBA1W7dm0tWLBAd911lyTp559/VlRUlFatWqVevXrpk08+UUJCgjIyMhQZGSlJSkpK0rBhw5Sdna2goKBL2mZubq5cLpdycnIueRkAACpKg/ErK7oEj+19oW+Zr7O079+lvmalsLBQSUlJysvLU2xsrLZu3apTp04pPj7e6hMZGamYmBilpqZKktLS0hQTE2MFFUnq1auX8vPztXXr1vNuKz8/X7m5uW4TAAC4OngcVr7//nvVqFFDTqdTjzzyiJYuXapmzZopKytLvr6+qlmzplv/sLAwZWVlSZKysrIUFhbmNr9mzZry9fW1+pRk6tSpcrlc1hQVFeVp2QAAoJLyOKw0btxY6enp2rRpkx599FENHTpUO3bsOG9/Y4wcDof1+Ox/n6/PuSZMmKCcnBxrysjI8LRsAABQSXl7uoCvr6+uu+46SVK7du20efNmzZw5U3fddZcKCgp05MgRt7Mr2dnZ6tixoyQpPDxcX375pdv6jhw5olOnThU743I2p9Mpp9PpaakAAKAKuOzvWTHGKD8/X23btpWPj49SUlKseZmZmdq2bZsVVmJjY7Vt2zZlZmZafVavXi2n06m2bdtebikAAKAK8ujMypNPPqnevXsrKipKx44dU1JSktavX6/k5GS5XC498MADGjt2rGrVqqXg4GCNGzdOzZs3V48ePSRJ8fHxatasmRITEzVt2jQdPnxY48aN0/Dhw7mrBwAAlMijsHLgwAElJiYqMzNTLpdLLVq0UHJysnr27ClJevXVV+Xt7a0777xTJ06cUPfu3TV//nx5eXlJkry8vLRy5UqNGDFCnTp1kr+/vwYPHqyXX3657PcMAABUCZf9PSsVge9ZAQBUJnzPym+u+PesAAAAXAmEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGuEFQAAYGsehZWpU6fqxhtvVGBgoEJDQ/W73/1OO3fudOsTFxcnh8PhNg0aNMitz5EjR5SYmCiXyyWXy6XExEQdPXr08vcGAABUOR6FlQ0bNmjkyJHatGmTUlJSdPr0acXHxysvL8+t3/Dhw5WZmWlNb731ltv8wYMHKz09XcnJyUpOTlZ6eroSExMvf28AAECV4+1J5+TkZLfH8+bNU2hoqLZu3apbbrnFaq9evbrCw8NLXMcPP/yg5ORkbdq0Se3bt5ckzZkzR7Gxsdq5c6caN27s6T4AAIAq7LKuWcnJyZEkBQcHu7UvWrRIISEhuuGGGzRu3DgdO3bMmpeWliaXy2UFFUnq0KGDXC6XUlNTS9xOfn6+cnNz3SYAAHB18OjMytmMMRozZow6d+6smJgYq33IkCGKjo5WeHi4tm3bpgkTJujbb79VSkqKJCkrK0uhoaHF1hcaGqqsrKwStzV16lRNnjy5tKUCAIBKrNRhZdSoUfruu++0ceNGt/bhw4db/46JiVGjRo3Url07ff3112rTpo0kyeFwFFufMabEdkmaMGGCxowZYz3Ozc1VVFRUaUsHAACVSKnCymOPPably5fr888/V926dS/Yt02bNvLx8dGuXbvUpk0bhYeH68CBA8X6HTx4UGFhYSWuw+l0yul0lqZUAABQyXl0zYoxRqNGjdKSJUu0bt06RUdHX3SZ7du369SpU4qIiJAkxcbGKicnR1999ZXV58svv1ROTo46duzoYfkAAKCq8+jMysiRI/Xee+/po48+UmBgoHWNicvlkr+/v3788UctWrRIffr0UUhIiHbs2KGxY8eqdevW6tSpkySpadOmuvXWWzV8+HDrluaHHnpICQkJ3AkEAACK8ejMyuzZs5WTk6O4uDhFRERY0/vvvy9J8vX11dq1a9WrVy81btxYjz/+uOLj47VmzRp5eXlZ61m0aJGaN2+u+Ph4xcfHq0WLFlqwYEHZ7hkAAKgSPDqzYoy54PyoqCht2LDhousJDg7WwoULPdk0AAC4SvHbQAAAwNYIKwAAwNZK/T0rAID/p8H4lRVdgsf2vtC3oksALglnVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK1x6zIA26mMtwEDKD+cWQEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALZGWAEAALbmUViZOnWqbrzxRgUGBio0NFS/+93vtHPnTrc++fn5euyxxxQSEqKAgAD1799f+/fvd+uzb98+9evXTwEBAQoJCdHjjz+ugoKCy98bAABQ5XgUVjZs2KCRI0dq06ZNSklJ0enTpxUfH6+8vDyrz+jRo7V06VIlJSVp48aNOn78uBISElRYWChJKiwsVN++fZWXl6eNGzcqKSlJixcv1tixY8t2zwAAQJXgMMaY0i588OBBhYaGasOGDbrllluUk5Oj2rVra8GCBbrrrrskST///LOioqK0atUq9erVS5988okSEhKUkZGhyMhISVJSUpKGDRum7OxsBQUFXXS7ubm5crlcysnJuaT+wNWswfiVFV0CbGrvC30ruoSrRmV8HZbH8VHa9+/LumYlJydHkhQcHCxJ2rp1q06dOqX4+HirT2RkpGJiYpSamipJSktLU0xMjBVUJKlXr17Kz8/X1q1bS9xOfn6+cnNz3SYAAHB1KHVYMcZozJgx6ty5s2JiYiRJWVlZ8vX1Vc2aNd36hoWFKSsry+oTFhbmNr9mzZry9fW1+pxr6tSpcrlc1hQVFVXasgEAQCVT6rAyatQofffdd/rHP/5x0b7GGDkcDuvx2f8+X5+zTZgwQTk5OdaUkZFR2rIBAEAlU6qw8thjj2n58uX67LPPVLduXas9PDxcBQUFOnLkiFv/7Oxs62xKeHh4sTMoR44c0alTp4qdcSnidDoVFBTkNgEAgKuDR2HFGKNRo0ZpyZIlWrdunaKjo93mt23bVj4+PkpJSbHaMjMztW3bNnXs2FGSFBsbq23btikzM9Pqs3r1ajmdTrVt2/Zy9gUAAFRB3p50HjlypN577z199NFHCgwMtM6QuFwu+fv7y+Vy6YEHHtDYsWNVq1YtBQcHa9y4cWrevLl69OghSYqPj1ezZs2UmJioadOm6fDhwxo3bpyGDx/OGRMAAFCMR2Fl9uzZkqS4uDi39nnz5mnYsGGSpFdffVXe3t668847deLECXXv3l3z58+Xl5eXJMnLy0srV67UiBEj1KlTJ/n7+2vw4MF6+eWXL39vAABAleNRWLmUr2Tx8/PTrFmzNGvWrPP2qVevnlasWOHJpgEAwFWK3wYCAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC25l3RBQAAKkaD8SsrugSP7X2hb0WXgArAmRUAAGBrHoeVzz//XP369VNkZKQcDoeWLVvmNn/YsGFyOBxuU4cOHdz65Ofn67HHHlNISIgCAgLUv39/7d+///L2BAAAVEkeh5W8vDy1bNlSr7322nn73HrrrcrMzLSmVatWuc0fPXq0li5dqqSkJG3cuFHHjx9XQkKCCgsLPd8DAABQpXl8zUrv3r3Vu3fvC/ZxOp0KDw8vcV5OTo7mzp2rBQsWqEePHpKkhQsXKioqSmvWrFGvXr08LQkAAFRh5XLNyvr16xUaGqrrr79ew4cPV3Z2tjVv69atOnXqlOLj4622yMhIxcTEKDU1tcT15efnKzc3120CAABXhzK/G6h37976/e9/r/r162vPnj16+umn1a1bN23dulVOp1NZWVny9fVVzZo13ZYLCwtTVlZWieucOnWqJk+eXNalAh6rjHdPAEBlV+Zh5a677rL+HRMTo3bt2ql+/fpauXKl7rjjjvMuZ4yRw+Eocd6ECRM0ZswY63Fubq6ioqLKrmgAAGBb5X7rckREhOrXr69du3ZJksLDw1VQUKAjR4649cvOzlZYWFiJ63A6nQoKCnKbAADA1aHcw8qhQ4eUkZGhiIgISVLbtm3l4+OjlJQUq09mZqa2bdumjh07lnc5AACgkvH4Y6Djx49r9+7d1uM9e/YoPT1dwcHBCg4O1qRJkzRgwABFRERo7969evLJJxUSEqLbb79dkuRyufTAAw9o7NixqlWrloKDgzVu3Dg1b97cujsIAACgiMdhZcuWLeratav1uOhakqFDh2r27Nn6/vvv9e677+ro0aOKiIhQ165d9f777yswMNBa5tVXX5W3t7fuvPNOnThxQt27d9f8+fPl5eVVBrsEAACqEo/DSlxcnIwx553/6aefXnQdfn5+mjVrlmbNmuXp5gEAwFWG3wYCAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC2RlgBAAC25l3RBQAAcKkajF9Z0SWgAnBmBQAA2BphBQAA2JrHYeXzzz9Xv379FBkZKYfDoWXLlrnNN8Zo0qRJioyMlL+/v+Li4rR9+3a3PkeOHFFiYqJcLpdcLpcSExN19OjRy9sTAABQJXkcVvLy8tSyZUu99tprJc5/6aWXNH36dL322mvavHmzwsPD1bNnTx07dszqM3jwYKWnpys5OVnJyclKT09XYmJi6fcCAABUWR5fYNu7d2/17t27xHnGGM2YMUNPPfWU7rjjDknSO++8o7CwML333nt6+OGH9cMPPyg5OVmbNm1S+/btJUlz5sxRbGysdu7cqcaNG1/G7gAAgKqmTK9Z2bNnj7KyshQfH2+1OZ1OdenSRampqZKktLQ0uVwuK6hIUocOHeRyuaw+58rPz1dubq7bBAAArg5lGlaysrIkSWFhYW7tYWFh1rysrCyFhoYWWzY0NNTqc66pU6da17e4XC5FRUWVZdkAAMDGyuVuIIfD4fbYGOPWdu78kvqcbcKECcrJybGmjIyMsi0YAADYVpl+KVx4eLik386eREREWO3Z2dnW2Zbw8HAdOHCg2LIHDx4sdkamiNPplNPpLMtSAQBAJVGmZ1aio6MVHh6ulJQUq62goEAbNmxQx44dJUmxsbHKycnRV199ZfX58ssvlZOTY/UBAAAo4vGZlePHj2v37t3W4z179ig9PV3BwcGqV6+eRo8erSlTpqhRo0Zq1KiRpkyZourVq2vw4MGSpKZNm+rWW2/V8OHD9dZbb0mSHnroISUkJHAnEAAAKMbjsLJlyxZ17drVejxmzBhJ0tChQzV//nz96U9/0okTJzRixAgdOXJE7du31+rVqxUYGGgts2jRIj3++OPWXUP9+/c/7/e2AACAq5vDGGMqughP5ebmyuVyKScnR0FBQRVdDq4i/IgagKvF3hf6lvk6S/v+zW8DAQAAWyOsAAAAWyOsAAAAWyOsAAAAWyOsAAAAWyOsAAAAWyOsAAAAWyOsAAAAWyOsAAAAWyOsAAAAWyOsAAAAW/P4hwyBssLv7AAALgVnVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK0RVgAAgK2VeViZNGmSHA6H2xQeHm7NN8Zo0qRJioyMlL+/v+Li4rR9+/ayLgMAAFQR5XJm5YYbblBmZqY1ff/999a8l156SdOnT9drr72mzZs3Kzw8XD179tSxY8fKoxQAAFDJlUtY8fb2Vnh4uDXVrl1b0m9nVWbMmKGnnnpKd9xxh2JiYvTOO+/o119/1XvvvVcepQAAgEquXMLKrl27FBkZqejoaA0aNEg//fSTJGnPnj3KyspSfHy81dfpdKpLly5KTU097/ry8/OVm5vrNgEAgKtDmYeV9u3b691339Wnn36qOXPmKCsrSx07dtShQ4eUlZUlSQoLC3NbJiwszJpXkqlTp8rlcllTVFRUWZcNAABsqszDSu/evTVgwAA1b95cPXr00MqVKyVJ77zzjtXH4XC4LWOMKdZ2tgkTJignJ8eaMjIyyrpsAABgU+V+63JAQICaN2+uXbt2WXcFnXsWJTs7u9jZlrM5nU4FBQW5TQAA4OpQ7mElPz9fP/zwgyIiIhQdHa3w8HClpKRY8wsKCrRhwwZ17NixvEsBAACVkHdZr3DcuHHq16+f6tWrp+zsbD333HPKzc3V0KFD5XA4NHr0aE2ZMkWNGjVSo0aNNGXKFFWvXl2DBw8u61IAAEAVUOZhZf/+/br77rv1yy+/qHbt2urQoYM2bdqk+vXrS5L+9Kc/6cSJExoxYoSOHDmi9u3ba/Xq1QoMDCzrUgAAQBXgMMaYii7CU7m5uXK5XMrJyeH6lUqswfiVFV0CAOA89r7Qt8zXWdr3b34bCAAA2BphBQAA2BphBQAA2BphBQAA2BphBQAA2BphBQAA2FqZf88KKga3AQMAqirOrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFsjrAAAAFvzrugC7KjB+JUVXQIAAPj/cWYFAADYGmEFAADYGmEFAADYGmEFAADYWoWGlTfeeEPR0dHy8/NT27Zt9cUXX1RkOQAAwIYqLKy8//77Gj16tJ566il98803uvnmm9W7d2/t27evokoCAAA2VGFhZfr06XrggQf04IMPqmnTppoxY4aioqI0e/bsiioJAADYUIV8z0pBQYG2bt2q8ePHu7XHx8crNTW1WP/8/Hzl5+dbj3NyciRJubm55VLfmfxfy2W9AABUFuXxHlu0TmOMR8tVSFj55ZdfVFhYqLCwMLf2sLAwZWVlFes/depUTZ48uVh7VFRUudUIAMDVzDWj/NZ97NgxuVyuS+5fod9g63A43B4bY4q1SdKECRM0ZswY6/GZM2d0+PBh1apVq8T+dpSbm6uoqChlZGQoKCioosupUhjb8sPYlh/GtvwwtuXncsfWGKNjx44pMjLSo+UqJKyEhITIy8ur2FmU7OzsYmdbJMnpdMrpdLq1XXPNNeVaY3kJCgrixVNOGNvyw9iWH8a2/DC25edyxtaTMypFKuQCW19fX7Vt21YpKSlu7SkpKerYsWNFlAQAAGyqwj4GGjNmjBITE9WuXTvFxsbq7bff1r59+/TII49UVEkAAMCGvCZNmjSpIjYcExOjWrVqacqUKXr55Zd14sQJLViwQC1btqyIcq4ILy8vxcXFydubH7sua4xt+WFsyw9jW34Y2/JTEWPrMJ7ePwQAAHAF8dtAAADA1ggrAADA1ggrAADA1ggrAADA1ggrAADA1ggrZeiNN95QdHS0/Pz81LZtW33xxRfn7Tt//nw5HI5i08mTJ69gxZWHJ2MrSUePHtXIkSMVEREhPz8/NW3aVKtWrbpC1VYunoxtXFxcicdt3759r2DFlYenx+2MGTPUuHFj+fv7KyoqSk888QR/E87Dk7E9deqU/vKXv6hhw4by8/NTy5YtlZycfAWrrTw+//xz9evXT5GRkXI4HFq2bNlFl9mwYYPatm0rPz8/XXvttXrzzTfLvjCDMpGUlGR8fHzMnDlzzI4dO8wf/vAHExAQYP773/+W2H/evHkmKCjIZGZmuk0oztOxzc/PN+3atTN9+vQxGzduNHv37jVffPGFSU9Pv8KV25+nY3vo0CG343Xbtm3Gy8vLzJs378oWXgl4OrYLFy40TqfTLFq0yOzZs8d8+umnJiIiwowePfoKV25/no7tn/70JxMZGWlWrlxpfvzxR/PGG28YPz8/8/XXX1/hyu1v1apV5qmnnjKLFy82kszSpUsv2P+nn34y1atXN3/4wx/Mjh07zJw5c4yPj4/55z//WaZ1EVbKyE033WQeeeQRt7YmTZqY8ePHl9h/3rx5xuVyXYnSKj1Px3b27Nnm2muvNQUFBVeivErN07E916uvvmoCAwPN8ePHy6O8Ss3TsR05cqTp1q2bW9uYMWNM586dy63GysrTsY2IiDCvvfaaW9ttt91mhgwZUm41VgWXElb+9Kc/mSZNmri1Pfzww6ZDhw5lWgsfA5WBgoICbd26VfHx8W7t8fHxSk1NPe9yx48fV/369VW3bl0lJCTom2++Ke9SK53SjO3y5csVGxurkSNHKiwsTDExMZoyZYoKCwuvRMmVRmmP27PNnTtXgwYNUkBAQHmUWGmVZmw7d+6srVu36quvvpIk/fTTT1q1ahUfsZ2jNGObn58vPz8/tzZ/f39t3Lix3Oq8WqSlpRV7Lnr16qUtW7bo1KlTZbYdvoe4DPzyyy8qLCws9ovRYWFhxX5ZukiTJk00f/58NW/eXLm5uZo5c6Y6deqkb7/9Vo0aNboSZVcKpRnbn376SevWrdOQIUO0atUq7dq1SyNHjtTp06f1zDPPXImyK4XSjO3ZvvrqK23btk1z584trxIrrdKM7aBBg3Tw4EF17txZxhidPn1ajz76qMaPH38lSq40SjO2vXr10vTp03XLLbeoYcOGWrt2rT766CP+A1MGsrKySnwuTp8+rV9++UURERFlsh3OrJQhh8Ph9tgYU6ytSIcOHXTPPfeoZcuWuvnmm/XBBx/o+uuv16xZs65EqZWOJ2N75swZhYaG6u2331bbtm01aNAgPfXUU5o9e/aVKLXS8WRszzZ37lzFxMTopptuKq/SKj1Pxnb9+vV6/vnn9cYbb+jrr7/WkiVLtGLFCj377LNXotRKx5OxnTlzpho1aqQmTZrI19dXo0aN0n333ScvL68rUWqVV9JzUVL75eDMShkICQmRl5dXsVSfnZ1dLHGeT7Vq1XTjjTdq165d5VFipVWasY2IiJCPj4/bH6KmTZsqKytLBQUF8vX1LdeaK4vLOW5//fVXJSUl6S9/+Ut5llhplWZsn376aSUmJurBBx+UJDVv3lx5eXl66KGH9NRTT6laNf5vKZVubGvXrq1ly5bp5MmTOnTokCIjIzV+/HhFR0dfiZKrtPDw8BKfC29vb9WqVavMtsPRXwZ8fX3Vtm1bpaSkuLWnpKSoY8eOl7QOY4zS09PL7JRZVVGase3UqZN2796tM2fOWG3/+c9/FBERQVA5y+Uctx988IHy8/N1zz33lGeJlVZpxvbXX38tFki8vLxkfrsRotxqrWwu57j18/NTnTp1dPr0aS1evFi33XZbeZZ6VYiNjS32XKxevVrt2rWTj49P2W2oTC/XvYoV3Uo3d+5cs2PHDjN69GgTEBBg9u7da4wxJjEx0e1K9UmTJpnk5GTz448/mm+++cbcd999xtvb23z55ZcVtQu25enY7tu3z9SoUcOMGjXK7Ny506xYscKEhoaa5557rqJ2wbY8HdsinTt3NnfdddeVLrdS8XRsJ06caAIDA80//vEP89NPP5nVq1ebhg0bmjvvvLOidsG2PB3bTZs2mcWLF5sff/zRfP7556Zbt24mOjraHDlypKJ2wbaOHTtmvvnmG/PNN98YSWb69Onmm2++sW4LHz9+vElMTLT6F926/MQTT5gdO3aYuXPncuuy3b3++uumfv36xtfX17Rp08Zs2LDBmtelSxczdOhQ6/Ho0aNNvXr1jK+vr6ldu7aJj483qampFVB15eDJ2BpjTGpqqmnfvr1xOp3m2muvNc8//7w5ffr0Fa66cvB0bHfu3GkkmdWrV1/hSisfT8b21KlTZtKkSaZhw4bGz8/PREVFmREjRvCGeh6ejO369etN06ZNjdPpNLVq1TKJiYnmf//7XwVUbX+fffaZkVRsKhrPoUOHmi5durgts379etO6dWvj6+trGjRoYGbPnl3mdTmM4fwiAACwL65ZAQAAtkZYAQAAtkZYAQAAtkZYAQAAtkZYAQAAtkZYAQAAtkZYAQAAtkZYAQAAtkZYAQAAtkZYAQAAtkZYAQAAtvb/AbtggDuuNDr7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_scores = pd.Series(pd.read_pickle('new_scores.pickle')[0])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "print(\"Total fake names: \",len(fake_scores))\n",
    "print(\"Total 90% or less match: \",len(fake_scores[fake_scores < 0.9]))\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.title('Disitribution of fake wine names to real ones')\n",
    "plt.hist(fake_scores.values)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
