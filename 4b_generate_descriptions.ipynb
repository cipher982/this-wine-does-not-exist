{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:42:02.590401Z",
     "start_time": "2020-08-20T13:41:59.954360Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tokenizer and fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T15:12:05.619166Z",
     "start_time": "2020-08-20T15:12:03.784048Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = transformers.GPT2Tokenizer.from_pretrained(\"gpt2_distil_output/\")\n",
    "model = transformers.GPT2LMHeadModel.from_pretrained(\n",
    "  \"gpt2_distil_output/checkpoint-37500/\",\n",
    "  pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "#model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T15:12:05.650167Z",
     "start_time": "2020-08-20T15:12:05.636167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|startoftext|>',\n",
       " 'eos_token': '<|startoftext|>',\n",
       " 'unk_token': '<|endoftext|>'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:43:00.653794Z",
     "start_time": "2020-08-20T13:43:00.549792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  tensor([[50257, 50258, 21902,   353,  9530,   741, 14496,   303,    68, 47535,\n",
      "           344,   609, 19917,    77,   323,  1853, 50259]])\n",
      "<|startoftext|> [prompt] Walter Hansel Cuvee Alyce Chardonnay 2015 [response] Walter Han\n"
     ]
    }
   ],
   "source": [
    "input_prompt = \"<|startoftext|> [prompt] Walter Hansel Cuvee Alyce Chardonnay 2015 [response] \"\n",
    "input_ids = tokenizer.encode(input_prompt, return_tensors='pt')\n",
    "print(\"Tokens: \", input_ids)\n",
    "\n",
    "greedy_output = model.generate(input_ids)\n",
    "print(tokenizer.decode(greedy_output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T13:43:31.686011Z",
     "start_time": "2020-08-20T13:43:29.980854Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "--------------------------------------------------------------------------------\n",
      "====================\n",
      "0: [prompt] Walter Hansel Cuvee Alyce Chardonnay 2015 [response] Aromas of white peach, apricot, and honeydew melon. On the palate, the wine is rich and full-bodied, with flavors of ripe apple, pear, vanilla cream and toasted hazelnut.\t\n",
      "\n",
      "\n",
      "====================\n",
      "1: [prompt] Walter Hansel Cuvee Alyce Chardonnay 2015 [response] Aromas of white peach, apricot, and honeydew melon. On the palate, the wine is rich and full-bodied, with flavors of ripe apple, pear, vanilla cream and toasty oak.\t\n",
      "\n",
      "\n",
      "====================\n",
      "2: [prompt] Walter Hansel Cuvee Alyce Chardonnay 2015 [response] Aromas of white peach, apricot, and honeydew melon. On the palate, the wine is rich and full-bodied, with flavors of ripe apple, pear, vanilla cream and toasted hazelnut. The wine has a long, lingering finish.\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_prompt = \"<|startoftext|> [prompt] Walter Hansel Cuvee Alyce Chardonnay 2015 [response] \"\n",
    "input_ids = tokenizer.encode(input_prompt, return_tensors='pt')\n",
    "\n",
    "# activate beam search and early_stopping\n",
    "beam_outputs = model.generate(\n",
    "  input_ids, \n",
    "  max_length=200, \n",
    "  num_beams=5, \n",
    "  no_repeat_ngram_size=2,\n",
    "  num_return_sequences=3, \n",
    "  early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 80 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"=\"*20)\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sampling Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T16:14:21.316299Z",
     "start_time": "2020-08-20T16:14:20.245290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[50257, 50258,    53,   437,   858,   609, 19917,    77,   323, 50259]])\n",
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "====================\n",
      "[prompt] Vendange Chardonnay [response] Vendange Chardonnay is a lively, medium-bodied wine with aromas and flavors of apple, pear, and melon. The oak adds to the wine's weight and texture while enhancing the fruit and butter flavors. A rich, buttery mid-palate and long finish make this Chardonnay an excellent match for creamy pastas, chicken dishes, and rich cream based pastas.\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_prompt = \"<|startoftext|> \" + \"[prompt] \" + \"Vendange Chardonnay \" + \"[response] \"\n",
    "input_ids = tokenizer.encode(input_prompt, return_tensors='pt')\n",
    "print(input_ids)\n",
    "\n",
    "# Send to GPU\n",
    "model.to('cuda:1')\n",
    "input_ids = input_ids.to('cuda:1')\n",
    "\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=250, \n",
    "    top_p=0.8,\n",
    "    top_k=200,\n",
    "    temperature=0.9,\n",
    "    eos_token_id=50257,\n",
    "    bos_token_id=50257,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(\"=\"*20)\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate descriptions on fake wine names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T15:18:51.837581Z",
     "start_time": "2020-08-20T15:18:51.801582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13301, 2)\n"
     ]
    }
   ],
   "source": [
    "fake_names = pd.read_csv(\"data/fake/fake_names_13301_2020-05-20.csv\")\n",
    "print(fake_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T16:03:30.717048Z",
     "start_time": "2020-08-20T16:03:30.700023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Lachos Cellars Sauvignon Blanc 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dry Estated Bios de Bourting Sannero (375ML ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Tarodahadin Chaary Rivi 2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0\n",
       "0           0                Lachos Cellars Sauvignon Blanc 2012\n",
       "1           1  Dry Estated Bios de Bourting Sannero (375ML ha...\n",
       "2           2                       Tarodahadin Chaary Rivi 2010"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_names.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-20T16:15:27.650Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|███████████████▉                                                                                                | 1887/13301 [17:56<2:02:33,  1.55it/s]"
     ]
    }
   ],
   "source": [
    "# Send to GPU\n",
    "model.to('cuda:1')\n",
    "input_ids = input_ids.to('cuda:1')\n",
    "\n",
    "generated_descriptions = {}\n",
    "for fake_name in tqdm.tqdm(fake_names.iloc[:,1]):\n",
    "  #print(fake_name)\n",
    "  \n",
    "  # Create token from fake wine name\n",
    "  input_ids = tokenizer.encode(\n",
    "    text=(\"<|startoftext|>\\t[prompt]\\t\" + fake_name + \"\\t\" + \"[response] \"), \n",
    "    return_tensors='pt'\n",
    "  ).to('cuda:1')\n",
    "  \n",
    "  # Generate a fake description based on the name\n",
    "  model_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=250, \n",
    "    top_p=0.8,\n",
    "    top_k=200,\n",
    "    temperature=0.9,\n",
    "    eos_token_id=50257,\n",
    "    bos_token_id=50257,\n",
    "    early_stopping=True\n",
    "  )\n",
    "  \n",
    "  generated_descriptions[fake_name] = tokenizer.decode(\n",
    "    token_ids=model_output[0], \n",
    "    skip_special_tokens=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T16:02:24.834630Z",
     "start_time": "2020-08-20T16:02:24.819630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 2)\n",
      "(184, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lachos Cellars Sauvignon Blanc 2012</td>\n",
       "      <td>Bright, crisp, and mouthwatering, the 2012 Sau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tarodahadin Chaary Rivi 2010</td>\n",
       "      <td>The Chaary (or \"\"Orvieto-variety\"\") is a blend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Le Valli Sis de Trach Sauvignon Blanc 2013</td>\n",
       "      <td>The nose is intense and complex, with intense ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fotes Jadot Sauvignon Blanc 2005</td>\n",
       "      <td>This is a perfect example of a New Zealand Sau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alarag Caleforno Rosso 2018</td>\n",
       "      <td>Ruby red with purple reflections. On the nose,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name  \\\n",
       "0         Lachos Cellars Sauvignon Blanc 2012   \n",
       "2                Tarodahadin Chaary Rivi 2010   \n",
       "3  Le Valli Sis de Trach Sauvignon Blanc 2013   \n",
       "4            Fotes Jadot Sauvignon Blanc 2005   \n",
       "5                 Alarag Caleforno Rosso 2018   \n",
       "\n",
       "                                         description  \n",
       "0  Bright, crisp, and mouthwatering, the 2012 Sau...  \n",
       "2  The Chaary (or \"\"Orvieto-variety\"\") is a blend...  \n",
       "3  The nose is intense and complex, with intense ...  \n",
       "4  This is a perfect example of a New Zealand Sau...  \n",
       "5  Ruby red with purple reflections. On the nose,...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.DataFrame.from_dict(generated_descriptions.items())\n",
    "wine_df.columns = ['name', 'description']\n",
    "print(wine_df.shape)\n",
    "\n",
    "wine_df['description'] = wine_df['description'].str.split('\\[response\\]').str[1]\n",
    "wine_df['description'] = wine_df['description'].str.strip()\n",
    "wine_df['description'] = wine_df['description'].str.strip('\"')\n",
    "\n",
    "wine_df = wine_df[wine_df['description'].str.len() > 100]\n",
    "\n",
    "print(wine_df.shape)\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T16:02:25.677677Z",
     "start_time": "2020-08-20T16:02:25.670629Z"
    }
   },
   "outputs": [],
   "source": [
    "wine_df.to_csv(\"data/fake/fake_names_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
